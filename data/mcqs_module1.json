[
  {
      "question": "If \\( A \\) is an \\( n \\times n \\) matrix, which of the following is true about its determinant \\( \\det(A) \\)?",
      "options": [
          "It is always non-negative",
          "It is always positive",
          "It can be zero",
          "It can be negative"
      ],
      "answer": "It can be zero",
      "feedback": {
          "It is always non-negative": "Incorrect. The determinant can be negative.",
          "It is always positive": "Incorrect. The determinant can be zero or negative.",
          "It can be zero": "Correct! The determinant of a matrix can be zero.",
          "It can be negative": "Correct! The determinant of a matrix can be negative."
      }
  },
  {
      "question": "For a matrix \\( A \\), the rank is defined as:",
      "options": [
          "The number of rows",
          "The number of columns",
          "The maximum number of linearly independent rows or columns",
          "The sum of the diagonal elements"
      ],
      "answer": "The maximum number of linearly independent rows or columns",
      "feedback": {
          "The number of rows": "Incorrect. The rank is not simply the number of rows.",
          "The number of columns": "Incorrect. The rank is not simply the number of columns.",
          "The maximum number of linearly independent rows or columns": "Correct! The rank is the maximum number of linearly independent rows or columns.",
          "The sum of the diagonal elements": "Incorrect. The sum of the diagonal elements is called the trace, not the rank."
      }
  },
  {
      "question": "The eigenvalues of a matrix \\( A \\) are found by solving:",
      "options": [
          "\\( \\det(A - \\lambda I) = 0 \\)",
          "\\( \\det(A + \\lambda I) = 0 \\)",
          "\\( \\det(A) = \\lambda \\)",
          "\\( \\det(A) = 0 \\)"
      ],
      "answer": "\\( \\det(A - \\lambda I) = 0 \\)",
      "feedback": {
          "\\( \\det(A - \\lambda I) = 0 \\)": "Correct! Eigenvalues are found by solving \\( \\det(A - \\lambda I) = 0 \\).",
          "\\( \\det(A + \\lambda I) = 0 \\)": "Incorrect. This is not the correct equation to find eigenvalues.",
          "\\( \\det(A) = \\lambda \\)": "Incorrect. This is not the correct equation to find eigenvalues.",
          "\\( \\det(A) = 0 \\)": "Incorrect. This condition defines a singular matrix, not eigenvalues."
      }
  },
  {
      "question": "A vector \\( \\mathbf{v} \\) is in the null space of a matrix \\( A \\) if:",
      "options": [
          "\\( A\\mathbf{v} = 0 \\)",
          "\\( A\\mathbf{v} = \\mathbf{v} \\)",
          "\\( A\\mathbf{v} = \\mathbf{u} \\) for some non-zero vector \\( \\mathbf{u} \\)",
          "\\( A\\mathbf{v} = \\lambda \\mathbf{v} \\)"
      ],
      "answer": "\\( A\\mathbf{v} = 0 \\)",
      "feedback": {
          "\\( A\\mathbf{v} = 0 \\)": "Correct! A vector is in the null space of a matrix if \\( A\\mathbf{v} = 0 \\).",
          "\\( A\\mathbf{v} = \\mathbf{v} \\)": "Incorrect. This describes an eigenvector with eigenvalue 1.",
          "\\( A\\mathbf{v} = \\mathbf{u} \\) for some non-zero vector \\( \\mathbf{u} \\)": "Incorrect. This does not describe the null space condition.",
          "\\( A\\mathbf{v} = \\lambda \\mathbf{v} \\)": "Incorrect. This describes an eigenvector with eigenvalue \\( \\lambda \\)."
      }
  },
  {
      "question": "The gradient of a scalar field \\( f \\) is a:",
      "options": [
          "Scalar",
          "Vector",
          "Matrix",
          "Tensor"
      ],
      "answer": "Vector",
      "feedback": {
          "Scalar": "Incorrect. The gradient is a vector.",
          "Vector": "Correct! The gradient of a scalar field is a vector.",
          "Matrix": "Incorrect. The gradient is not a matrix.",
          "Tensor": "Incorrect. The gradient is specifically a vector."
      }
  },
  {
      "question": "In probability, the law of large numbers states that as the number of trials increases:",
      "options": [
          "The sample mean approaches the population mean",
          "The sample variance approaches the population variance",
          "The probability of each event approaches 0.5",
          "The sample median approaches the population median"
      ],
      "answer": "The sample mean approaches the population mean",
      "feedback": {
          "The sample mean approaches the population mean": "Correct! The law of large numbers states that the sample mean approaches the population mean as the number of trials increases.",
          "The sample variance approaches the population variance": "Incorrect. The law of large numbers is about the mean, not the variance.",
          "The probability of each event approaches 0.5": "Incorrect. The law of large numbers does not state this.",
          "The sample median approaches the population median": "Incorrect. The law of large numbers is about the mean, not the median."
      }
  },
  {
      "question": "The cumulative distribution function (CDF) of a random variable \\( X \\) gives:",
      "options": [
          "The probability density at \\( X \\)",
          "The probability that \\( X \\) takes on a specific value",
          "The probability that \\( X \\) is less than or equal to a certain value",
          "The expected value of \\( X \\)"
      ],
      "answer": "The probability that \\( X \\) is less than or equal to a certain value",
      "feedback": {
          "The probability density at \\( X \\)": "Incorrect. The PDF gives the probability density.",
          "The probability that \\( X \\) takes on a specific value": "Incorrect. The CDF gives the cumulative probability.",
          "The probability that \\( X \\) is less than or equal to a certain value": "Correct! The CDF gives the probability that \\( X \\) is less than or equal to a certain value.",
          "The expected value of \\( X \\)": "Incorrect. The CDF does not give the expected value."
      }
  },
  {
      "question": "The Bayes' theorem relates:",
      "options": [
          "The joint probability and the marginal probability",
          "The prior probability and the posterior probability",
          "The likelihood and the conditional probability",
          "The mean and the variance"
      ],
      "answer": "The prior probability and the posterior probability",
      "feedback": {
          "The joint probability and the marginal probability": "Incorrect. Bayes' theorem relates prior and posterior probabilities.",
          "The prior probability and the posterior probability": "Correct! Bayes' theorem relates the prior probability and the posterior probability.",
          "The likelihood and the conditional probability": "Incorrect. Bayes' theorem uses likelihood but relates prior and posterior probabilities.",
          "The mean and the variance": "Incorrect. Bayes' theorem does not relate mean and variance."
      }
  },
  {
      "question": "The principal component analysis (PCA) aims to:",
      "options": [
          "Maximize the variance of the data",
          "Minimize the variance of the data",
          "Maximize the correlation between features",
          "Minimize the correlation between features"
      ],
      "answer": "Maximize the variance of the data",
      "feedback": {
          "Maximize the variance of the data": "Correct! PCA aims to maximize the variance of the data along the principal components.",
          "Minimize the variance of the data": "Incorrect. PCA aims to maximize the variance.",
          "Maximize the correlation between features": "Incorrect. PCA aims to reduce correlation by transforming features.",
          "Minimize the correlation between features": "Incorrect. PCA reduces correlation but its primary goal is to maximize variance."
      }
  },
  {
      "question": "A researcher wants to identify different species of plants in a forest using drone images. Which machine learning method should they use?",
      "options": [
          "Supervised Learning",
          "Unsupervised Learning",
          "Reinforcement Learning",
          "Self-supervised Learning"
      ],
      "answer": "Supervised Learning",
      "feedback": {
          "Supervised Learning": "Correct! Supervised learning is used for identifying different species of plants based on labeled data.",
          "Unsupervised Learning": "Incorrect. Supervised learning involves labeled data, which is appropriate for species identification.",
          "Reinforcement Learning": "Incorrect. Reinforcement learning involves learning through rewards and penalties.",
          "Self-supervised Learning": "Incorrect. Self-supervised learning involves creating labels from the data itself."
      }
  },
  {
      "question": "Which operation cannot be performed on a matrix?",
      "options": [
          "Addition",
          "Multiplication",
          "Subtraction",
          "Differentiation"
      ],
      "answer": "Differentiation",
      "feedback": {
          "Addition": "Incorrect. Addition of matrices is a valid operation.",
          "Multiplication": "Incorrect. Multiplication of matrices is a valid operation.",
          "Subtraction": "Incorrect. Subtraction of matrices is a valid operation.",
          "Differentiation": "Correct! Differentiation is not typically defined for matrices."
      }
  },
  {
      "question": "What characterizes a subspace of a vector space?",
      "options": [
          "Not containing the zero vector",
          "Being closed under addition and scalar multiplication",
          "Being infinite",
          "Having at least one vector"
      ],
      "answer": "Being closed under addition and scalar multiplication",
      "feedback": {
          "Not containing the zero vector": "Incorrect. A subspace must contain the zero vector.",
          "Being closed under addition and scalar multiplication": "Correct! A subspace is closed under addition and scalar multiplication.",
          "Being infinite": "Incorrect. A subspace does not have to be infinite.",
          "Having at least one vector": "Incorrect. Having at least one vector does not fully define a subspace."
      }
  },
  {
      "question": "What does the concept of entropy in information theory quantify?",
      "options": [
          "Energy",
          "Probability",
          "Uncertainty",
          "Correlation"
      ],
      "answer": "Uncertainty",
      "feedback": {
          "Energy": "Incorrect. Entropy in information theory is not about energy.",
          "Probability": "Incorrect. Entropy uses probabilities but quantifies uncertainty.",
          "Uncertainty": "Correct! Entropy quantifies uncertainty.",
          "Correlation": "Incorrect. Entropy is not about correlation."
      }
  },
  {
      "question": "What does the derivative of a function \\( f(x) \\) represent?",
      "options": [
          "The area under the curve of \\( f(x) \\)",
          "The slope of the tangent line to \\( f(x) \\)",
          "The value of \\( f(x) \\) at \\( x \\)",
          "The maximum value of \\( f(x) \\)"
      ],
      "answer": "The slope of the tangent line to \\( f(x) \\)",
      "feedback": {
          "The area under the curve of \\( f(x) \\)": "Incorrect. The integral represents the area under the curve.",
          "The slope of the tangent line to \\( f(x) \\)": "Correct! The derivative represents the slope of the tangent line.",
          "The value of \\( f(x) \\) at \\( x \\)": "Incorrect. The derivative is not the value of the function.",
          "The maximum value of \\( f(x) \\)": "Incorrect. The derivative can help find maxima, but it is not the maximum value."
      }
  },
  {
      "question": "What is the purpose of gradient descent?",
      "options": [
          "Find the maximum of a function",
          "Find the minimum of a function",
          "Calculate the derivative of a function",
          "Integrate a function"
      ],
      "answer": "Find the minimum of a function",
      "feedback": {
          "Find the maximum of a function": "Incorrect. Gradient descent is used to find the minimum, not the maximum.",
          "Find the minimum of a function": "Correct! Gradient descent is used to find the minimum of a function.",
          "Calculate the derivative of a function": "Incorrect. Gradient descent uses the derivative but does not calculate it.",
          "Integrate a function": "Incorrect. Gradient descent is not used for integration."
      }
  },
  {
      "question": "In stochastic gradient descent, what does the term 'stochastic' refer to?",
      "options": [
          "The use of all data points",
          "The use of random data points",
          "The use of batch data points",
          "The use of sequential data points"
      ],
      "answer": "The use of random data points",
      "feedback": {
          "The use of all data points": "Incorrect. This describes batch gradient descent, not stochastic gradient descent.",
          "The use of random data points": "Correct! Stochastic gradient descent uses random data points.",
          "The use of batch data points": "Incorrect. This describes mini-batch gradient descent, not stochastic gradient descent.",
          "The use of sequential data points": "Incorrect. Stochastic gradient descent does not necessarily use sequential data points."
      }
  },
  {
      "question": "A function \\( f(x) \\) is convex if:",
      "options": [
          "Its second derivative is positive",
          "Its first derivative is negative",
          "Its second derivative is zero",
          "It has a local minimum"
      ],
      "answer": "Its second derivative is positive",
      "feedback": {
          "Its second derivative is positive": "Correct! A function is convex if its second derivative is positive.",
          "Its first derivative is negative": "Incorrect. This is not the condition for convexity.",
          "Its second derivative is zero": "Incorrect. This would mean the function is linear, not necessarily convex.",
          "It has a local minimum": "Incorrect. Having a local minimum does not necessarily mean the function is convex."
      }
  },
  {
      "question": "The ADAM optimizer combines the ideas of:",
      "options": [
          "Momentum and learning rate decay",
          "Batch normalization and dropout",
          "Gradient clipping and weight decay",
          "RMSprop and Momentum"
      ],
      "answer": "RMSprop and Momentum",
      "feedback": {
          "Momentum and learning rate decay": "Incorrect. ADAM specifically combines RMSprop and Momentum, not learning rate decay.",
          "Batch normalization and dropout": "Incorrect. These are techniques to improve training but not part of ADAM.",
          "Gradient clipping and weight decay": "Incorrect. These are techniques to prevent issues during training but not part of ADAM.",
          "RMSprop and Momentum": "Correct! ADAM combines the ideas of RMSprop and Momentum."
      }
  },
  {
      "question": "A projection matrix \\( P \\) satisfies:",
      "options": [
          "\\( P^2 = P \\)",
          "\\( P^T = P \\)",
          "\\( P^{-1} = P \\)",
          "\\( P^T P = I \\)"
      ],
      "answer": "\\( P^2 = P \\)",
      "feedback": {
          "\\( P^2 = P \\)": "Correct! A projection matrix satisfies \\( P^2 = P \\).",
          "\\( P^T = P \\)": "Incorrect. This is true for symmetric matrices, not specifically projection matrices.",
          "\\( P^{-1} = P \\)": "Incorrect. This is true for involutory matrices, not projection matrices.",
          "\\( P^T P = I \\)": "Incorrect. This is true for orthogonal matrices, not projection matrices."
      }
  },
  {
      "question": "A vector is orthogonal to another vector if:",
      "options": [
          "Their dot product is zero",
          "Their cross product is zero",
          "Their sum is zero",
          "Their difference is zero"
      ],
      "answer": "Their dot product is zero",
      "feedback": {
          "Their dot product is zero": "Correct! Two vectors are orthogonal if their dot product is zero.",
          "Their cross product is zero": "Incorrect. This condition applies to parallel vectors, not orthogonal vectors.",
          "Their sum is zero": "Incorrect. This condition does not define orthogonality.",
          "Their difference is zero": "Incorrect. This condition does not define orthogonality."
      }
  },
  {
      "question": "The QR factorization of a matrix \\( A \\) results in:",
      "options": [
          "\\( A = QR \\), where \\( Q \\) is an orthogonal matrix and \\( R \\) is an upper triangular matrix",
          "\\( A = QR \\), where \\( Q \\) is an upper triangular matrix and \\( R \\) is an orthogonal matrix",
          "\\( A = QR \\), where \\( Q \\) and \\( R \\) are both orthogonal matrices",
          "\\( A = QR \\), where \\( Q \\) and \\( R \\) are both upper triangular matrices"
      ],
      "answer": "\\( A = QR \\), where \\( Q \\) is an orthogonal matrix and \\( R \\) is an upper triangular matrix",
      "feedback": {
          "\\( A = QR \\), where \\( Q \\) is an orthogonal matrix and \\( R \\) is an upper triangular matrix": "Correct! QR factorization results in \\( A = QR \\), where \\( Q \\) is orthogonal and \\( R \\) is upper triangular.",
          "\\( A = QR \\), where \\( Q \\) is an upper triangular matrix and \\( R \\) is an orthogonal matrix": "Incorrect. In QR factorization, \\( Q \\) is orthogonal and \\( R \\) is upper triangular.",
          "\\( A = QR \\), where \\( Q \\) and \\( R \\) are both orthogonal matrices": "Incorrect. In QR factorization, \\( Q \\) is orthogonal and \\( R \\) is upper triangular.",
          "\\( A = QR \\), where \\( Q \\) and \\( R \\) are both upper triangular matrices": "Incorrect. In QR factorization, \\( Q \\) is orthogonal and \\( R \\) is upper triangular."
      }
  },
  {
      "question": "A function \\( f(x) \\) is convex if:",
      "options": [
          "Its second derivative is positive",
          "Its first derivative is negative",
          "Its second derivative is zero",
          "It has a local minimum"
      ],
      "answer": "Its second derivative is positive",
      "feedback": {
          "Its second derivative is positive": "Correct! A function is convex if its second derivative is positive.",
          "Its first derivative is negative": "Incorrect. This is not the condition for convexity.",
          "Its second derivative is zero": "Incorrect. This would mean the function is linear, not necessarily convex.",
          "It has a local minimum": "Incorrect. Having a local minimum does not necessarily mean the function is convex."
      }
  },
  {
      "question": "What information do the eigenvalues of a matrix provide?",
      "options": [
          "Diagonal elements",
          "Singular values",
          "Characteristic polynomial",
          "Inverse"
      ],
      "answer": "Characteristic polynomial",
      "feedback": {
          "Diagonal elements": "Incorrect. The eigenvalues are related to the characteristic polynomial, not just the diagonal elements.",
          "Singular values": "Incorrect. Singular values are obtained from SVD.",
          "Characteristic polynomial": "Correct! Eigenvalues are roots of the characteristic polynomial.",
          "Inverse": "Incorrect. The eigenvalues do not directly provide information about the inverse."
      }
  },
  {
      "question": "What is the determinant of a 2x2 matrix \\(\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\\)?",
      "options": [
          "ad - bc",
          "ab - cd",
          "ac - bd",
          "a + d"
      ],
      "answer": "ad - bc",
      "feedback": {
          "ad - bc": "Correct! The determinant of a 2x2 matrix is given by ad - bc.",
          "ab - cd": "Incorrect. This is not the formula for the determinant.",
          "ac - bd": "Incorrect. This is not the formula for the determinant.",
          "a + d": "Incorrect. This is not the formula for the determinant."
      }
  },
  {
      "question": "What is the concept of rank in linear algebra related to?",
      "options": [
          "The number of non-zero rows in row echelon form",
          "The number of zero rows in row echelon form",
          "The determinant of the matrix",
          "The trace of the matrix"
      ],
      "answer": "The number of non-zero rows in row echelon form",
      "feedback": {
          "The number of non-zero rows in row echelon form": "Correct! Rank is the number of non-zero rows in row echelon form.",
          "The number of zero rows in row echelon form": "Incorrect. Rank is defined by the number of non-zero rows.",
          "The determinant of the matrix": "Incorrect. The determinant is a scalar value, not related to rank.",
          "The trace of the matrix": "Incorrect. The trace is the sum of the diagonal elements, not the rank."
      }
  },
  {
      "question": "What does the central limit theorem state about the distribution of the sample mean?",
      "options": [
          "It approaches a normal distribution as the sample size decreases",
          "It approaches a normal distribution as the sample size increases",
          "It approaches a normal distribution as the population mean increases",
          "It approaches a normal distribution as the population variance decreases"
      ],
      "answer": "It approaches a normal distribution as the sample size increases",
      "feedback": {
          "It approaches a normal distribution as the sample size decreases": "Incorrect. The central limit theorem requires a large sample size.",
          "It approaches a normal distribution as the sample size increases": "Correct! The distribution of the sample mean approaches a normal distribution as the sample size increases.",
          "It approaches a normal distribution as the population mean increases": "Incorrect. The central limit theorem is about sample size, not population mean.",
          "It approaches a normal distribution as the population variance decreases": "Incorrect. The central limit theorem is about sample size, not population variance."
      }
  },
  {
      "question": "Which type of random variables is the probability density function (PDF) used to describe?",
      "options": [
          "Discrete random variables",
          "Continuous random variables",
          "The mean of a random variable",
          "The variance of a random variable"
      ],
      "answer": "Continuous random variables",
      "feedback": {
          "Discrete random variables": "Incorrect. The probability mass function (PMF) is used for discrete random variables.",
          "Continuous random variables": "Correct! The PDF describes continuous random variables.",
          "The mean of a random variable": "Incorrect. The PDF does not describe the mean.",
          "The variance of a random variable": "Incorrect. The PDF does not describe the variance."
      }
  },
  {
      "question": "What does the mode of a distribution represent in statistics?",
      "options": [
          "The average value",
          "The middle value",
          "The most frequently occurring value",
          "The spread of values"
      ],
      "answer": "The most frequently occurring value",
      "feedback": {
          "The average value": "Incorrect. The average value is the mean.",
          "The middle value": "Incorrect. The middle value is the median.",
          "The most frequently occurring value": "Correct! The mode is the most frequently occurring value.",
          "The spread of values": "Incorrect. The spread of values is described by the variance or standard deviation."
      }
  },
  {
      "question": "Which function describes the likelihood of a continuous random variable taking on a range of values?",
      "options": [
          "Probability Mass Function (PMF)",
          "Cumulative Distribution Function (CDF)",
          "Probability Density Function (PDF)",
          "Likelihood Function"
      ],
      "answer": "Probability Density Function (PDF)",
      "feedback": {
          "Probability Mass Function (PMF)": "Incorrect. PMF is for discrete random variables.",
          "Cumulative Distribution Function (CDF)": "Incorrect. CDF is the cumulative probability of a random variable.",
          "Probability Density Function (PDF)": "Correct! PDF is for a continuous random variable taking on a range of values.",
          "Likelihood Function": "Incorrect. The likelihood function is for parameter estimation."
      }
  },
  {
      "question": "In a medical diagnosis system, a model predicts if a patient has a certain disease based on their medical history and test results. Which machine learning paradigm is suitable for this task?",
      "options": [
          "Supervised Learning",
          "Unsupervised Learning",
          "Reinforcement Learning",
          "Self-supervised Learning"
      ],
      "answer": "Supervised Learning",
      "feedback": {
          "Supervised Learning": "Correct! Supervised learning is for predicting diseases based on medical history and test results.",
          "Unsupervised Learning": "Incorrect. Unsupervised learning is for tasks like clustering and association.",
          "Reinforcement Learning": "Incorrect. Reinforcement learning is about learning through rewards and penalties.",
          "Self-supervised Learning": "Incorrect. Self-supervised learning is about creating labels from the data itself."
      }
  },
  {
      "question": "What do the eigenvalues of a matrix provide information about?",
      "options": [
          "Diagonal elements",
          "Singular values",
          "Characteristic polynomial",
          "Inverse"
      ],
      "answer": "Characteristic polynomial",
      "feedback": {
          "Diagonal elements": "Incorrect. The eigenvalues are related to the characteristic polynomial, not just the diagonal elements.",
          "Singular values": "Incorrect. Singular values are from SVD.",
          "Characteristic polynomial": "Correct! Eigenvalues are roots of the characteristic polynomial.",
          "Inverse": "Incorrect. The eigenvalues do not directly provide information about the inverse."
      }
  },
  {
      "question": "What are the columns and rows of an orthogonal matrix in linear algebra?",
      "options": [
          "Linearly dependent",
          "Unit vectors",
          "Orthonormal",
          "Positive definite"
      ],
      "answer": "Orthonormal",
      "feedback": {
          "Linearly dependent": "Incorrect. The columns and rows of an orthogonal matrix are linearly independent.",
          "Unit vectors": "Incorrect. The columns and rows are orthonormal vectors, which are unit vectors with orthogonality.",
          "Orthonormal": "Correct! The columns and rows of an orthogonal matrix are orthonormal.",
          "Positive definite": "Incorrect. Orthogonality does not imply positive definiteness."
      }
  },
  {
      "question": "What is the determinant of a 2x2 matrix \\(\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\\)?",
      "options": [
          "ad - bc",
          "ab - cd",
          "ac - bd",
          "a + d"
      ],
      "answer": "ad - bc",
      "feedback": {
          "ad - bc": "Correct! The determinant of a 2x2 matrix is given by ad - bc.",
          "ab - cd": "Incorrect. This is not the formula for the determinant.",
          "ac - bd": "Incorrect. This is not the formula for the determinant.",
          "a + d": "Incorrect. This is not the formula for the determinant."
      }
  },
  {
      "question": "What is the concept of rank in linear algebra related to?",
      "options": [
          "The number of non-zero rows in row echelon form",
          "The number of zero rows in row echelon form",
          "The determinant of the matrix",
          "The trace of the matrix"
      ],
      "answer": "The number of non-zero rows in row echelon form",
      "feedback": {
          "The number of non-zero rows in row echelon form": "Correct! Rank is the number of non-zero rows in row echelon form.",
          "The number of zero rows in row echelon form": "Incorrect. Rank is defined by the number of non-zero rows.",
          "The determinant of the matrix": "Incorrect. The determinant is a scalar value, not related to rank.",
          "The trace of the matrix": "Incorrect. The trace is the sum of the diagonal elements, not the rank."
      }
  },
  {
      "question": "What does the central limit theorem state about the distribution of the sample mean?",
      "options": [
          "It approaches a normal distribution as the sample size decreases",
          "It approaches a normal distribution as the sample size increases",
          "It approaches a normal distribution as the population mean increases",
          "It approaches a normal distribution as the population variance decreases"
      ],
      "answer": "It approaches a normal distribution as the sample size increases",
      "feedback": {
          "It approaches a normal distribution as the sample size decreases": "Incorrect. The central limit theorem requires a large sample size.",
          "It approaches a normal distribution as the sample size increases": "Correct! The distribution of the sample mean approaches a normal distribution as the sample size increases.",
          "It approaches a normal distribution as the population mean increases": "Incorrect. The central limit theorem is about sample size, not population mean.",
          "It approaches a normal distribution as the population variance decreases": "Incorrect. The central limit theorem is about sample size, not population variance."
      }
  },
  {
      "question": "What type of random variables is the probability density function (PDF) used to describe?",
      "options": [
          "Discrete random variables",
          "Continuous random variables",
          "The mean of a random variable",
          "The variance of a random variable"
      ],
      "answer": "Continuous random variables",
      "feedback": {
          "Discrete random variables": "Incorrect. The probability mass function (PMF) is used for discrete random variables.",
          "Continuous random variables": "Correct! The PDF describes continuous random variables.",
          "The mean of a random variable": "Incorrect. The PDF does not describe the mean.",
          "The variance of a random variable": "Incorrect. The PDF does not describe the variance."
      }
  },
  {
      "question": "What is the mode of a distribution in statistics?",
      "options": [
          "The average value",
          "The middle value",
          "The most frequently occurring value",
          "The spread of values"
      ],
      "answer": "The most frequently occurring value",
      "feedback": {
          "The average value": "Incorrect. The average value is the mean.",
          "The middle value": "Incorrect. The middle value is the median.",
          "The most frequently occurring value": "Correct! The mode is the most frequently occurring value.",
          "The spread of values": "Incorrect. The spread of values is described by the variance or standard deviation."
      }
  },
  {
      "question": "When are two events in probability considered mutually exclusive?",
      "options": [
          "When they cannot occur at the same time",
          "When the occurrence of one affects the probability of the other",
          "When they are independent",
          "When they have the same probability"
      ],
      "answer": "When they cannot occur at the same time",
      "feedback": {
          "When they cannot occur at the same time": "Correct! Mutually exclusive events cannot occur at the same time.",
          "When the occurrence of one affects the probability of the other": "Incorrect. This describes dependent events.",
          "When they are independent": "Incorrect. Independent events can occur at the same time.",
          "When they have the same probability": "Incorrect. Mutually exclusive events do not necessarily have the same probability."
      }
  },
  {
      "question": "What does the covariance between two variables measure?",
      "options": [
          "The average of the variables",
          "The spread of the variables",
          "The linear relationship between the variables",
          "The probability of the variables"
      ],
      "answer": "The linear relationship between the variables",
      "feedback": {
          "The average of the variables": "Incorrect. The average is not related to covariance.",
          "The spread of the variables": "Incorrect. The spread is measured by variance, not covariance.",
          "The linear relationship between the variables": "Correct! Covariance measures the linear relationship between two variables.",
          "The probability of the variables": "Incorrect. Covariance is not related to the probability."
      }
  },
  {
      "question": "Entropy in information theory is a measure of:",
      "options": [
          "Energy",
          "Information content",
          "Probability",
          "Variance"
      ],
      "answer": "Information content",
      "feedback": {
          "Energy": "Incorrect. Entropy in information theory is not about energy.",
          "Information content": "Correct! Entropy measures the information content or uncertainty.",
          "Probability": "Incorrect. Entropy uses probabilities but is not a probability.",
          "Variance": "Incorrect. Entropy is not the same as variance."
      }
  },
  {
      "question": "Mutual information quantifies the amount of information obtained about one random variable through:",
      "options": [
          "Its entropy",
          "Its variance",
          "Its correlation",
          "The other random variable"
      ],
      "answer": "The other random variable",
      "feedback": {
          "Its entropy": "Incorrect. Entropy measures uncertainty, not mutual information.",
          "Its variance": "Incorrect. Variance measures spread, not mutual information.",
          "Its correlation": "Incorrect. Correlation measures linear relationship, not mutual information.",
          "The other random variable": "Correct! Mutual information quantifies information obtained about one variable through the other."
      }
  },
  {
      "question": "Gradient descent is an optimization algorithm used to:",
      "options": [
          "Maximize a function",
          "Minimize a function",
          "Find the root of a function",
          "Integrate a function"
      ],
      "answer": "Minimize a function",
      "feedback": {
          "Maximize a function": "Incorrect. Gradient descent is used to minimize a function.",
          "Minimize a function": "Correct! Gradient descent is used to find the minimum of a function.",
          "Find the root of a function": "Incorrect. Gradient descent is not used for root finding.",
          "Integrate a function": "Incorrect. Gradient descent is not used for integration."
      }
  },
  {
      "question": "The ADAM optimizer combines the ideas of:",
      "options": [
          "Momentum and learning rate decay",
          "Batch normalization and dropout",
          "Gradient clipping and weight decay",
          "RMSprop and Momentum"
      ],
      "answer": "RMSprop and Momentum",
      "feedback": {
          "Momentum and learning rate decay": "Incorrect. ADAM specifically combines RMSprop and Momentum.",
          "Batch normalization and dropout": "Incorrect. These are techniques to improve training but not part of ADAM.",
          "Gradient clipping and weight decay": "Incorrect. These are techniques to prevent issues during training but not part of ADAM.",
          "RMSprop and Momentum": "Correct! ADAM combines the ideas of RMSprop and Momentum."
      }
  },
  {
      "question": "In convex optimization, a function is convex if:",
      "options": [
          "Its second derivative is positive",
          "Its first derivative is zero",
          "Its second derivative is zero",
          "It has a global minimum"
      ],
      "answer": "Its second derivative is positive",
      "feedback": {
          "Its second derivative is positive": "Correct! A function is convex if its second derivative is positive.",
          "Its first derivative is zero": "Incorrect. This condition does not define convexity.",
          "Its second derivative is zero": "Incorrect. This condition does not define convexity.",
          "It has a global minimum": "Incorrect. Convex functions are known for having a global minimum."
      }
  },
  {
      "question": "What is the principal component analysis (PCA) primarily used for?",
      "options": [
          "Classifying data",
          "Reducing the dimensionality of data",
          "Clustering data",
          "Performing regression"
      ],
      "answer": "Reducing the dimensionality of data",
      "feedback": {
          "Classifying data": "Incorrect. PCA is not primarily used for classification.",
          "Reducing the dimensionality of data": "Correct! PCA is primarily used for dimensionality reduction.",
          "Clustering data": "Incorrect. PCA is not primarily used for clustering.",
          "Performing regression": "Incorrect. PCA is not primarily used for regression."
      }
  },
  {
      "question": "In linear algebra, what does the null space of a matrix \\(A\\) represent?",
      "options": [
          "The set of all vectors \\(\\mathbf{x}\\) such that \\(A\\mathbf{x} = \\mathbf{0}\\)",
          "The set of all vectors \\(\\mathbf{x}\\) such that \\(A\\mathbf{x} = \\mathbf{x}\\)",
          "The set of all vectors \\(\\mathbf{x}\\) such that \\(A\\mathbf{x} = \\lambda \\mathbf{x}\\)",
          "The set of all vectors \\(\\mathbf{x}\\) such that \\(A\\mathbf{x} = \\mathbf{b}\\)"
      ],
      "answer": "The set of all vectors \\(\\mathbf{x}\\) such that \\(A\\mathbf{x} = \\mathbf{0}\\)",
      "feedback": {
          "The set of all vectors \\(\\mathbf{x}\\) such that \\(A\\mathbf{x} = \\mathbf{0}\\)": "Correct! The null space is the set of all vectors that are mapped to zero.",
          "The set of all vectors \\(\\mathbf{x}\\) such that \\(A\\mathbf{x} = \\mathbf{x}\\)": "Incorrect. This describes eigenvectors with eigenvalue 1, not the null space.",
          "The set of all vectors \\(\\mathbf{x}\\) such that \\(A\\mathbf{x} = \\lambda \\mathbf{x}\\)": "Incorrect. This describes eigenvectors with eigenvalue \\(\\lambda\\), not the null space.",
          "The set of all vectors \\(\\mathbf{x}\\) such that \\(A\\mathbf{x} = \\mathbf{b}\\)": "Incorrect. This describes the solution set of a linear system, not the null space."
      }
  },
  {
      "question": "What does the law of large numbers state about the sample mean as the number of trials increases?",
      "options": [
          "The sample mean approaches the population mean",
          "The sample variance approaches the population variance",
          "The probability of each event approaches 0.5",
          "The sample median approaches the population median"
      ],
      "answer": "The sample mean approaches the population mean",
      "feedback": {
          "The sample mean approaches the population mean": "Correct! The law of large numbers states that the sample mean approaches the population mean as the number of trials increases.",
          "The sample variance approaches the population variance": "Incorrect. The law of large numbers is about the mean, not the variance.",
          "The probability of each event approaches 0.5": "Incorrect. The law of large numbers does not state this.",
          "The sample median approaches the population median": "Incorrect. The law of large numbers is about the mean, not the median."
      }
  },
  {
      "question": "What is a random variable in probability theory?",
      "options": [
          "A deterministic quantity",
          "A function that assigns values to outcomes of a random experiment",
          "A quantity that is always discrete",
          "A quantity that is always continuous"
      ],
      "answer": "A function that assigns values to outcomes of a random experiment",
      "feedback": {
          "A deterministic quantity": "Incorrect. A random variable is not deterministic.",
          "A function that assigns values to outcomes of a random experiment": "Correct! A random variable assigns values to outcomes of a random experiment.",
          "A quantity that is always discrete": "Incorrect. A random variable can be either discrete or continuous.",
          "A quantity that is always continuous": "Incorrect. A random variable can be either continuous or discrete."
      }
  },
  {
      "question": "What does the cumulative distribution function (CDF) of a random variable \\( X \\) represent?",
      "options": [
          "The probability density at \\( X \\)",
          "The probability that \\( X \\) takes on a specific value",
          "The probability that \\( X \\) is less than or equal to a certain value",
          "The expected value of \\( X \\)"
      ],
      "answer": "The probability that \\( X \\) is less than or equal to a certain value",
      "feedback": {
          "The probability density at \\( X \\)": "Incorrect. The PDF gives the probability density, not the CDF.",
          "The probability that \\( X \\) takes on a specific value": "Incorrect. The CDF gives the cumulative probability, not the probability of a specific value.",
          "The probability that \\( X \\) is less than or equal to a certain value": "Correct! The CDF gives the probability that \\( X \\) is less than or equal to a certain value.",
          "The expected value of \\( X \\)": "Incorrect. The CDF does not give the expected value."
      }
  },
  {
      "question": "What does the Bayes' theorem relate?",
      "options": [
          "The joint probability and the marginal probability",
          "The prior probability and the posterior probability",
          "The likelihood and the conditional probability",
          "The mean and the variance"
      ],
      "answer": "The prior probability and the posterior probability",
      "feedback": {
          "The joint probability and the marginal probability": "Incorrect. Bayes' theorem relates prior and posterior probabilities, not joint and marginal probabilities.",
          "The prior probability and the posterior probability": "Correct! Bayes' theorem relates the prior probability and the posterior probability.",
          "The likelihood and the conditional probability": "Incorrect. Bayes' theorem uses likelihood but relates prior and posterior probabilities, not likelihood and conditional probability.",
          "The mean and the variance": "Incorrect. Bayes' theorem does not relate mean and variance."
      }
  },
  {
      "question": "What is the primary aim of the principal component analysis (PCA)?",
      "options": [
          "Maximize the variance of the data",
          "Minimize the variance of the data",
          "Maximize the correlation between features",
          "Minimize the correlation between features"
      ],
      "answer": "Maximize the variance of the data",
      "feedback": {
          "Maximize the variance of the data": "Correct! PCA aims to maximize the variance of the data along the principal components.",
          "Minimize the variance of the data": "Incorrect. PCA aims to maximize the variance, not minimize it.",
          "Maximize the correlation between features": "Incorrect. PCA aims to reduce correlation by transforming features, not maximize it.",
          "Minimize the correlation between features": "Incorrect. PCA reduces correlation but its primary goal is not to minimize correlation but to maximize variance."
      }
  },
  {
      "question": "Which machine learning paradigm primarily involves learning from labeled data?",
      "options": [
          "Supervised Learning",
          "Unsupervised Learning",
          "Reinforcement Learning",
          "Self-supervised Learning"
      ],
      "answer": "Supervised Learning",
      "feedback": {
          "Supervised Learning": "Correct! Supervised learning primarily involves learning from labeled data.",
          "Unsupervised Learning": "Incorrect. Unsupervised learning primarily involves learning from unlabeled data.",
          "Reinforcement Learning": "Incorrect. Reinforcement learning primarily involves learning from rewards and punishments, not labeled data.",
          "Self-supervised Learning": "Incorrect. Self-supervised learning involves creating labels from the data itself, not learning from labeled data."
      }
  },
  {
      "question": "Which method is primarily used to solve a system of linear equations?",
      "options": [
          "Gradient Descent",
          "Singular Value Decomposition",
          "Gaussian Elimination",
          "Principal Component Analysis"
      ],
      "answer": "Gaussian Elimination",
      "feedback": {
          "Gradient Descent": "Incorrect. Gradient descent is primarily used for optimization problems, not solving systems of linear equations.",
          "Singular Value Decomposition": "Incorrect. SVD is primarily used for matrix factorization, not solving systems of linear equations.",
          "Gaussian Elimination": "Correct! Gaussian elimination is primarily used to solve systems of linear equations.",
          "Principal Component Analysis": "Incorrect. PCA is primarily used for dimensionality reduction, not solving systems of linear equations."
      }
  },
  {
      "question": "What do the eigenvalues of a matrix provide information about?",
      "options": [
          "Diagonal elements",
          "Singular values",
          "Characteristic polynomial",
          "Inverse"
      ],
      "answer": "Characteristic polynomial",
      "feedback": {
          "Diagonal elements": "Incorrect. The eigenvalues are related to the characteristic polynomial, not just the diagonal elements.",
          "Singular values": "Incorrect. Singular values are obtained from SVD, not from eigenvalues.",
          "Characteristic polynomial": "Correct! Eigenvalues are roots of the characteristic polynomial.",
          "Inverse": "Incorrect. The eigenvalues do not directly provide information about the inverse of a matrix."
      }
  },
  {
      "question": "What does the determinant of a matrix help determine?",
      "options": [
          "If the matrix is orthogonal",
          "If the matrix is invertible",
          "If the matrix is diagonalizable",
          "If the matrix is positive definite"
      ],
      "answer": "If the matrix is invertible",
      "feedback": {
          "If the matrix is orthogonal": "Incorrect. The determinant does not determine if a matrix is orthogonal.",
          "If the matrix is invertible": "Correct! If the determinant is non-zero, the matrix is invertible.",
          "If the matrix is diagonalizable": "Incorrect. The determinant does not determine if a matrix is diagonalizable.",
          "If the matrix is positive definite": "Incorrect. The determinant alone does not determine if a matrix is positive definite."
      }
  },
  {
      "question": "What does the inner product of two vectors in an inner product space define?",
      "options": [
          "Orthogonality",
          "Normalization",
          "Eigenvalues",
          "Covariance"
      ],
      "answer": "Orthogonality",
      "feedback": {
          "Orthogonality": "Correct! The inner product is used to define orthogonality between vectors.",
          "Normalization": "Incorrect. Normalization uses the norm, not the inner product.",
          "Eigenvalues": "Incorrect. Eigenvalues are related to linear transformations.",
          "Covariance": "Incorrect. Covariance measures the relationship between two random variables."
      }
  },
  {
      "question": "What operations is a vector space closed under?",
      "options": [
          "Addition and scalar multiplication",
          "Addition and subtraction",
          "Multiplication and division",
          "Dot product and cross product"
      ],
      "answer": "Addition and scalar multiplication",
      "feedback": {
          "Addition and scalar multiplication": "Correct! A vector space is closed under addition and scalar multiplication.",
          "Addition and subtraction": "Incorrect. Subtraction can be seen as addition of the negative.",
          "Multiplication and division": "Incorrect. Vector spaces are not closed under multiplication and division.",
          "Dot product and cross product": "Incorrect. These operations do not define a vector space."
      }
  },
  {
      "question": "What does a distribution function (CDF) in probability describe?",
      "options": [
          "The probability of a random variable taking on a specific value",
          "The cumulative probability up to a certain value",
          "The density of a random variable",
          "The mean of a random variable"
      ],
      "answer": "The cumulative probability up to a certain value",
      "feedback": {
          "The probability of a random variable taking on a specific value": "Incorrect. The CDF gives the cumulative probability, not a specific value.",
          "The cumulative probability up to a certain value": "Correct! The CDF describes the cumulative probability up to a certain value.",
          "The density of a random variable": "Incorrect. The PDF describes the density.",
          "The mean of a random variable": "Incorrect. The mean is a measure of central tendency."
      }
  },
  {
      "question": "What does the joint distribution of two random variables describe?",
      "options": [
          "The marginal distribution of each variable",
          "The combined probability of both variables",
          "The conditional distribution of one variable given the other",
          "The independence of the two variables"
      ],
      "answer": "The combined probability of both variables",
      "feedback": {
          "The marginal distribution of each variable": "Incorrect. The joint distribution includes the combined probabilities.",
          "The combined probability of both variables": "Correct! The joint distribution describes the combined probability of both variables.",
          "The conditional distribution of one variable given the other": "Incorrect. This is the conditional distribution.",
          "The independence of the two variables": "Incorrect. The joint distribution does not imply independence."
      }
  },
  {
      "question": "What does the covariance between two variables measure?",
      "options": [
          "The average of the variables",
          "The spread of the variables",
          "The linear relationship between the variables",
          "The probability of the variables"
      ],
      "answer": "The linear relationship between the variables",
      "feedback": {
          "The average of the variables": "Incorrect. The average is not related to covariance.",
          "The spread of the variables": "Incorrect. The spread is measured by variance, not covariance.",
          "The linear relationship between the variables": "Correct! Covariance measures the linear relationship between two variables.",
          "The probability of the variables": "Incorrect. Covariance is not related to the probability."
      }
  },
  {
      "question": "What does the concept of independence in probability mean?",
      "options": [
          "The events cannot occur at the same time",
          "The occurrence of one event affects the probability of the other",
          "The events are mutually exclusive",
          "The occurrence of one event does not affect the probability of the other"
      ],
      "answer": "The occurrence of one event does not affect the probability of the other",
      "feedback": {
          "The events cannot occur at the same time": "Incorrect. This describes mutually exclusive events.",
          "The occurrence of one event affects the probability of the other": "Incorrect. This describes dependent events.",
          "The events are mutually exclusive": "Incorrect. This is not the definition of independence.",
          "The occurrence of one event does not affect the probability of the other": "Correct! Independent events do not affect each other's probability."
      }
  },
  {
      "question": "What does entropy in information theory quantify?",
      "options": [
          "The amount of data in a message",
          "The average length of a message",
          "The uncertainty in a random variable",
          "The redundancy in a message"
      ],
      "answer": "The uncertainty in a random variable",
      "feedback": {
          "The amount of data in a message": "Incorrect. Entropy measures uncertainty, not the amount of data.",
          "The average length of a message": "Incorrect. Entropy measures uncertainty, not length.",
          "The uncertainty in a random variable": "Correct! Entropy quantifies the uncertainty in a random variable.",
          "The redundancy in a message": "Incorrect. Entropy does not measure redundancy."
      }
  },
  {
      "question": "The concept of mutual information measures:",
      "options": [
          "The dependence between two random variables",
          "The uncertainty in a single variable",
          "The difference between two distributions",
          "The average value of a random variable"
      ],
      "answer": "The dependence between two random variables",
      "feedback": {
          "The dependence between two random variables": "Correct! Mutual information measures the dependence between two random variables.",
          "The uncertainty in a single variable": "Incorrect. This is measured by entropy.",
          "The difference between two distributions": "Incorrect. This is measured by KL divergence.",
          "The average value of a random variable": "Incorrect. This is the expected value."
      }
  },
  {
      "question": "What is the primary use of the Gradient descent optimization algorithm?",
      "options": [
          "To maximize a function",
          "To minimize a function",
          "To find the root of a function",
          "To integrate a function"
      ],
      "answer": "To minimize a function",
      "feedback": {
          "To maximize a function": "Incorrect. Gradient descent is used to minimize a function.",
          "To minimize a function": "Correct! Gradient descent is used to find the minimum of a function.",
          "To find the root of a function": "Incorrect. Gradient descent is not used for root finding.",
          "To integrate a function": "Incorrect. Gradient descent is not used for integration."
      }
  },
  {
      "question": "What does the ADAM optimizer, an extension of gradient descent, include?",
      "options": [
          "Momentum and learning rate adaptation",
          "Batch normalization and dropout",
          "Weight decay and gradient clipping",
          "Stochastic and mini-batch updates"
      ],
      "answer": "Momentum and learning rate adaptation",
      "feedback": {
          "Momentum and learning rate adaptation": "Correct! ADAM optimizer combines momentum and learning rate adaptation.",
          "Batch normalization and dropout": "Incorrect. These are techniques to improve training but not part of ADAM.",
          "Weight decay and gradient clipping": "Incorrect. These are techniques to prevent issues during training but not part of ADAM.",
          "Stochastic and mini-batch updates": "Incorrect. ADAM can use stochastic and mini-batch updates, but it's known for momentum and learning rate adaptation."
      }
  },
  {
      "question": "What is a characteristic of a convex function in convex optimization?",
      "options": [
          "It has multiple local minima",
          "It has a single global minimum",
          "It is always differentiable",
          "It is always continuous"
      ],
      "answer": "It has a single global minimum",
      "feedback": {
          "It has multiple local minima": "Incorrect. A convex function has no local minima.",
          "It has a single global minimum": "Correct! A convex function has a single global minimum.",
          "It is always differentiable": "Incorrect. Convex functions are not necessarily differentiable.",
          "It is always continuous": "Incorrect. Convex functions are not necessarily continuous."
      }
  },
  {
      "question": "What is the aim of the principal component analysis (PCA)?",
      "options": [
          "To maximize the variance of the data",
          "To minimize the variance of the data",
          "To maximize the correlation between features",
          "To minimize the correlation between features"
      ],
      "answer": "To maximize the variance of the data",
      "feedback": {
          "To maximize the variance of the data": "Correct! PCA aims to maximize the variance of the data along the principal components.",
          "To minimize the variance of the data": "Incorrect. PCA aims to maximize the variance.",
          "To maximize the correlation between features": "Incorrect. PCA aims to reduce correlation by transforming features.",
          "To minimize the correlation between features": "Incorrect. PCA reduces correlation but its primary goal is to maximize variance."
      }
  },
  {
      "question": "What does the singular value decomposition (SVD) of a matrix result in?",
      "options": [
          "A product of an orthogonal matrix, a diagonal matrix, and the transpose of an orthogonal matrix",
          "A product of a lower triangular matrix and an upper triangular matrix",
          "A product of an orthogonal matrix and an upper triangular matrix",
          "A product of a permutation matrix and an orthogonal matrix"
      ],
      "answer": "A product of an orthogonal matrix, a diagonal matrix, and the transpose of an orthogonal matrix",
      "feedback": {
          "A product of an orthogonal matrix, a diagonal matrix, and the transpose of an orthogonal matrix": "Correct! SVD results in a product of an orthogonal matrix, a diagonal matrix, and the transpose of an orthogonal matrix.",
          "A product of a lower triangular matrix and an upper triangular matrix": "Incorrect. This describes LU decomposition.",
          "A product of an orthogonal matrix and an upper triangular matrix": "Incorrect. This describes QR decomposition.",
          "A product of a permutation matrix and an orthogonal matrix": "Incorrect. This is not a common matrix factorization."
      }
  },
  {
      "question": "What is a characteristic of a positive definite matrix?",
      "options": [
          "All its eigenvalues are positive",
          "All its eigenvalues are negative",
          "All its eigenvalues are non-negative",
          "All its eigenvalues are non-positive"
      ],
      "answer": "All its eigenvalues are positive",
      "feedback": {
          "All its eigenvalues are positive": "Correct! A positive definite matrix has all positive eigenvalues.",
          "All its eigenvalues are negative": "Incorrect. A positive definite matrix cannot have negative eigenvalues.",
          "All its eigenvalues are non-negative": "Incorrect. This describes a positive semi-definite matrix.",
          "All its eigenvalues are non-positive": "Incorrect. This describes a negative semi-definite matrix."
      }
  },
  {
      "question": "A vector \\( \\mathbf{v} \\) is in the null space of a matrix \\( A \\) if:",
      "options": [
          "\\( A\\mathbf{v} = 0 \\)",
          "\\( A\\mathbf{v} = \\mathbf{v} \\)",
          "\\( A\\mathbf{v} = \\mathbf{u} \\) for some non-zero vector \\( \\mathbf{u} \\)",
          "\\( A\\mathbf{v} = \\lambda \\mathbf{v} \\)"
      ],
      "answer": "\\( A\\mathbf{v} = 0 \\)",
      "feedback": {
          "\\( A\\mathbf{v} = 0 \\)": "Correct! A vector is in the null space of a matrix if \\( A\\mathbf{v} = 0 \\).",
          "\\( A\\mathbf{v} = \\mathbf{v} \\)": "Incorrect. This describes an eigenvector with eigenvalue 1.",
          "\\( A\\mathbf{v} = \\mathbf{u} \\) for some non-zero vector \\( \\mathbf{u} \\)": "Incorrect. This does not describe the null space condition.",
          "\\( A\\mathbf{v} = \\lambda \\mathbf{v} \\)": "Incorrect. This describes an eigenvector with eigenvalue \\( \\lambda \\)."
      }
  },
  {
      "question": "The probability density function (PDF) of a continuous random variable:",
      "options": [
          "Gives the probability of the random variable taking on a specific value",
          "Gives the probability of the random variable taking on values in a given interval",
          "Is always equal to the cumulative distribution function (CDF)",
          "Is always greater than 1"
      ],
      "answer": "Gives the probability of the random variable taking on values in a given interval",
      "feedback": {
          "Gives the probability of the random variable taking on a specific value": "Incorrect. The PDF gives the probability density, not the probability of a specific value.",
          "Gives the probability of the random variable taking on values in a given interval": "Correct! The PDF gives the probability density over an interval.",
          "Is always equal to the cumulative distribution function (CDF)": "Incorrect. The PDF is the derivative of the CDF.",
          "Is always greater than 1": "Incorrect. The PDF can be less than or equal to 1."
      }
  },
  {
      "question": "Conditional probability \\(P(A|B)\\) is defined as:",
      "options": [
          "\\(P(A) + P(B)\\)",
          "\\(P(A) - P(B)\\)",
          "\\(P(A \\cap B) / P(B)\\)",
          "\\(P(A) / P(B)\\)"
      ],
      "answer": "\\(P(A \\cap B) / P(B)\\)",
      "feedback": {
          "\\(P(A) + P(B)\\)": "This is not the formula for conditional probability.",
          "\\(P(A) - P(B)\\)": "This is not the formula for conditional probability.",
          "\\(P(A \\cap B) / P(B)\\)": "Correct! This is the formula for conditional probability.",
          "\\(P(A) / P(B)\\)": "This is not the formula for conditional probability."
      }
  },
  {
      "question": "Covariance measures:",
      "options": [
          "The variance of a single variable",
          "The relationship between two variables",
          "The mean of a variable",
          "The standard deviation of a variable"
      ],
      "answer": "The relationship between two variables",
      "feedback": {
          "The variance of a single variable": "Incorrect. Covariance involves two variables, not just one.",
          "The relationship between two variables": "Correct! Covariance measures the relationship between two variables.",
          "The mean of a variable": "Incorrect. Covariance is not related to the mean.",
          "The standard deviation of a variable": "Incorrect. Covariance is not related to the standard deviation of a single variable."
      }
  },
  {
      "question": "Entropy in information theory quantifies:",
      "options": [
          "The amount of data in a message",
          "The average length of a message",
          "The uncertainty in a random variable",
          "The redundancy in a message"
      ],
      "answer": "The uncertainty in a random variable",
      "feedback": {
          "The amount of data in a message": "Incorrect. Entropy measures uncertainty, not the amount of data.",
          "The average length of a message": "Incorrect. Entropy measures uncertainty, not length.",
          "The uncertainty in a random variable": "Correct! Entropy quantifies the uncertainty in a random variable.",
          "The redundancy in a message": "Incorrect. Entropy does not measure redundancy."
      }
  },
  {
      "question": "Gradient descent is used to:",
      "options": [
          "Find the maximum of a function",
          "Find the minimum of a function",
          "Calculate the derivative of a function",
          "Integrate a function"
      ],
      "answer": "Find the minimum of a function",
      "feedback": {
          "Find the maximum of a function": "Incorrect. Gradient descent is used to find the minimum, not the maximum.",
          "Find the minimum of a function": "Correct! Gradient descent is used to find the minimum of a function.",
          "Calculate the derivative of a function": "Incorrect. Gradient descent uses the derivative but does not calculate it.",
          "Integrate a function": "Incorrect. Gradient descent is not used for integration."
      }
  },
  {
      "question": "A function \\( f(x) \\) is convex if:",
      "options": [
          "Its second derivative is positive",
          "Its first derivative is negative",
          "Its second derivative is zero",
          "It has a local minimum"
      ],
      "answer": "Its second derivative is positive",
      "feedback": {
          "Its second derivative is positive": "Correct! A function is convex if its second derivative is positive.",
          "Its first derivative is negative": "Incorrect. This is not the condition for convexity.",
          "Its second derivative is zero": "Incorrect. This would mean the function is linear, not necessarily convex.",
          "It has a local minimum": "Incorrect. Having a local minimum does not define convexity."
      }
  },
  {
      "question": "Which machine learning paradigm is primarily used for classification and regression tasks?",
      "options": [
          "Supervised Learning",
          "Unsupervised Learning",
          "Reinforcement Learning",
          "Dimensionality Reduction"
      ],
      "answer": "Supervised Learning",
      "feedback": {
          "Supervised Learning": "Correct! Supervised learning is used for classification and regression.",
          "Unsupervised Learning": "Incorrect. Unsupervised learning is used for clustering and association.",
          "Reinforcement Learning": "Incorrect. Reinforcement learning is used for decision-making tasks.",
          "Dimensionality Reduction": "Incorrect. Dimensionality reduction is a technique used to reduce the number of features."
      }
  },
  {
      "question": "A projection matrix \\( P \\) satisfies:",
      "options": [
          "\\( P^2 = P \\)",
          "\\( P^T = P \\)",
          "\\( P^{-1} = P \\)",
          "\\( P^T P = I \\)"
      ],
      "answer": "\\( P^2 = P \\)",
      "feedback": {
          "\\( P^2 = P \\)": "Correct! A projection matrix satisfies \\( P^2 = P \\).",
          "\\( P^T = P \\)": "Incorrect. This is true for symmetric matrices, not specifically projection matrices.",
          "\\( P^{-1} = P \\)": "Incorrect. This is true for involutory matrices, not projection matrices.",
          "\\( P^T P = I \\)": "Incorrect. This is true for orthogonal matrices, not projection matrices."
      }
  },
  {
      "question": "The eigenvalues of a matrix \\( A \\) are found by solving:",
      "options": [
          "\\( \\det(A - \\lambda I) = 0 \\)",
          "\\( \\det(A + \\lambda I) = 0 \\)",
          "\\( \\det(A) = \\lambda \\)",
          "\\( \\det(A) = 0 \\)"
      ],
      "answer": "\\( \\det(A - \\lambda I) = 0 \\)",
      "feedback": {
          "\\( \\det(A - \\lambda I) = 0 \\)": "Correct! Eigenvalues are found by solving \\( \\det(A - \\lambda I) = 0 \\).",
          "\\( \\det(A + \\lambda I) = 0 \\)": "Incorrect. This is not the correct equation to find eigenvalues.",
          "\\( \\det(A) = \\lambda \\)": "Incorrect. This is not the correct equation to find eigenvalues.",
          "\\( \\det(A) = 0 \\)": "Incorrect. This condition defines a singular matrix, not eigenvalues."
      }
  },
  {
      "question": "The QR factorization of a matrix \\( A \\) results in:",
      "options": [
          "\\( A = QR \\), where \\( Q \\) is an orthogonal matrix and \\( R \\) is an upper triangular matrix",
          "\\( A = QR \\), where \\( Q \\) is an upper triangular matrix and \\( R \\) is an orthogonal matrix",
          "\\( A = QR \\), where \\( Q \\) and \\( R \\) are both orthogonal matrices",
          "\\( A = QR \\), where \\( Q \\) and \\( R \\) are both upper triangular matrices"
      ],
      "answer": "\\( A = QR \\), where \\( Q \\) is an orthogonal matrix and \\( R \\) is an upper triangular matrix",
      "feedback": {
          "\\( A = QR \\), where \\( Q \\) is an orthogonal matrix and \\( R \\) is an upper triangular matrix": "Correct! QR factorization results in \\( A = QR \\), where \\( Q \\) is orthogonal and \\( R \\) is upper triangular.",
          "\\( A = QR \\), where \\( Q \\) is an upper triangular matrix and \\( R \\) is an orthogonal matrix": "Incorrect. In QR factorization, \\( Q \\) is orthogonal and \\( R \\) is upper triangular.",
          "\\( A = QR \\), where \\( Q \\) and \\( R \\) are both orthogonal matrices": "Incorrect. In QR factorization, \\( Q \\) is orthogonal and \\( R \\) is upper triangular.",
          "\\( A = QR \\), where \\( Q \\) and \\( R \\) are both upper triangular matrices": "Incorrect. In QR factorization, \\( Q \\) is orthogonal and \\( R \\) is upper triangular."
      }
  },
  {
      "question": "What conditions must be met for a function \\(f(x)\\) to have a local minimum at \\(x = c\\)?",
      "options": [
          "\\(f'(c) = 0\\) and \\(f''(c) > 0\\)",
          "\\(f'(c) = 0\\) and \\(f''(c) < 0\\)",
          "\\(f'(c) > 0\\) and \\(f''(c) > 0\\)",
          "\\(f'(c) < 0\\) and \\(f''(c) < 0\\)"
      ],
      "answer": "\\(f'(c) = 0\\) and \\(f''(c) > 0\\)",
      "feedback": {
          "\\(f'(c) = 0\\) and \\(f''(c) > 0\\)": "Correct! These conditions indicate a local minimum.",
          "\\(f'(c) = 0\\) and \\(f''(c) < 0\\)": "Incorrect. These conditions indicate a local maximum.",
          "\\(f'(c) > 0\\) and \\(f''(c) > 0\\)": "Incorrect. The first derivative must be zero at a local minimum.",
          "\\(f'(c) < 0\\) and \\(f''(c) < 0\\)": "Incorrect. The first derivative must be zero at a local minimum."
      }
  },
  {
      "question": "What does the singular value decomposition (SVD) of a matrix result in?",
      "options": [
          "A product of an orthogonal matrix, a diagonal matrix, and the transpose of an orthogonal matrix",
          "A product of a lower triangular matrix and an upper triangular matrix",
          "A product of an orthogonal matrix and an upper triangular matrix",
          "A product of a permutation matrix and an orthogonal matrix"
      ],
      "answer": "A product of an orthogonal matrix, a diagonal matrix, and the transpose of an orthogonal matrix",
      "feedback": {
          "A product of an orthogonal matrix, a diagonal matrix, and the transpose of an orthogonal matrix": "Correct! SVD results in a product of an orthogonal matrix, a diagonal matrix, and the transpose of an orthogonal matrix.",
          "A product of a lower triangular matrix and an upper triangular matrix": "Incorrect. This describes LU decomposition, not SVD.",
          "A product of an orthogonal matrix and an upper triangular matrix": "Incorrect. This describes QR decomposition, not SVD.",
          "A product of a permutation matrix and an orthogonal matrix": "Incorrect. This is not a common matrix factorization."
      }
  },
  {
      "question": "What does the method of maximum likelihood estimation (MLE) involve?",
      "options": [
          "Maximizing the posterior distribution",
          "Maximizing the likelihood function",
          "Maximizing the prior distribution",
          "Maximizing the cumulative distribution function (CDF)"
      ],
      "answer": "Maximizing the likelihood function",
      "feedback": {
          "Maximizing the posterior distribution": "Incorrect. This describes the method of maximum a posteriori (MAP), not MLE.",
          "Maximizing the likelihood function": "Correct! MLE involves maximizing the likelihood function.",
          "Maximizing the prior distribution": "Incorrect. The prior distribution is not maximized in MLE.",
          "Maximizing the cumulative distribution function (CDF)": "Incorrect. The CDF is not maximized in MLE."
      }
  },
  {
      "question": "In convex optimization, what is a characteristic of a convex function?",
      "options": [
          "Has multiple local minima",
          "Has a single global minimum",
          "Is always differentiable",
          "Is always continuous"
      ],
      "answer": "Has a single global minimum",
      "feedback": {
          "Has multiple local minima": "Incorrect. A convex function does not have local minima.",
          "Has a single global minimum": "Correct! A convex function has a single global minimum.",
          "Is always differentiable": "Incorrect. Convex functions are not necessarily differentiable.",
          "Is always continuous": "Incorrect. Convex functions are not necessarily continuous."
      }
  },
  {
      "question": "What is the cross-entropy loss function commonly used for?",
      "options": [
          "Classification tasks",
          "Regression tasks",
          "Clustering tasks",
          "Dimensionality reduction tasks"
      ],
      "answer": "Classification tasks",
      "feedback": {
          "Classification tasks": "Correct! The cross-entropy loss function is used for classification tasks.",
          "Regression tasks": "Incorrect. Mean squared error is commonly used for regression tasks, not the cross-entropy loss function.",
          "Clustering tasks": "Incorrect. The cross-entropy loss function is not used for clustering.",
          "Dimensionality reduction tasks": "Incorrect. The cross-entropy loss function is not used for dimensionality reduction."
      }
  },
  {
      "question": "Which machine learning paradigm is primarily used for classification and regression tasks?",
      "options": [
          "Supervised Learning",
          "Unsupervised Learning",
          "Reinforcement Learning",
          "Dimensionality Reduction"
      ],
      "answer": "Supervised Learning",
      "feedback": {
          "Supervised Learning": "Correct! Supervised learning is used for classification and regression.",
          "Unsupervised Learning": "Incorrect. Unsupervised learning is used for clustering and association, not for classification and regression.",
          "Reinforcement Learning": "Incorrect. Reinforcement learning is used for decision-making tasks, not for classification and regression.",
          "Dimensionality Reduction": "Incorrect. Dimensionality reduction is a technique used to reduce the number of features, not a machine learning paradigm for classification and regression."
      }
  },
  {
      "question": "In a vector space, when are two vectors considered linearly independent?",
      "options": [
          "Their dot product is zero",
          "Their cross product is zero",
          "No vector can be written as a linear combination of the other",
          "They have the same direction"
      ],
      "answer": "No vector can be written as a linear combination of the other",
      "feedback": {
          "Their dot product is zero": "Incorrect. This condition defines orthogonality, not linear independence.",
          "Their cross product is zero": "Incorrect. This condition applies to parallel vectors, not linearly independent vectors.",
          "No vector can be written as a linear combination of the other": "Correct! This is the definition of linear independence.",
          "They have the same direction": "Incorrect. Vectors with the same direction are linearly dependent, not linearly independent."
      }
  },
  {
      "question": "What method can be used to find the solution to a system of linear equations?",
      "options": [
          "Eigenvalue decomposition",
          "Singular value decomposition",
          "Gaussian elimination",
          "Matrix multiplication"
      ],
      "answer": "Gaussian elimination",
      "feedback": {
          "Eigenvalue decomposition": "Incorrect. Eigenvalue decomposition is used for matrix diagonalization, not for solving systems of linear equations.",
          "Singular value decomposition": "Incorrect. Singular value decomposition is used for matrix factorization, not for solving systems of linear equations.",
          "Gaussian elimination": "Correct! Gaussian elimination is used to solve systems of linear equations.",
          "Matrix multiplication": "Incorrect. Matrix multiplication is an operation, not a method for solving systems of linear equations."
      }
  },
  {
      "question": "What does the rank of a matrix represent?",
      "options": [
          "The total number of rows",
          "The total number of columns",
          "The count of linearly independent rows or columns",
          "The determinant of the matrix"
      ],
      "answer": "The count of linearly independent rows or columns",
      "feedback": {
          "The total number of rows": "Incorrect. The rank is not just the total number of rows.",
          "The total number of columns": "Incorrect. The rank is not just the total number of columns.",
          "The count of linearly independent rows or columns": "Correct! The rank represents the count of linearly independent rows or columns.",
          "The determinant of the matrix": "Incorrect. The determinant is a scalar value that represents certain properties of the matrix, not the rank."
      }
  },
  {
      "question": "How is the norm of a vector \\( \\mathbf{v} \\) defined?",
      "options": [
          "The length or magnitude of \\( \\mathbf{v} \\)",
          "The angle of \\( \\mathbf{v} \\)",
          "The direction of \\( \\mathbf{v} \\)",
          "The dot product of \\( \\mathbf{v} \\) with itself"
      ],
      "answer": "The length or magnitude of \\( \\mathbf{v} \\)",
      "feedback": {
          "The length or magnitude of \\( \\mathbf{v} \\)": "Correct! The norm of a vector is its length or magnitude.",
          "The angle of \\( \\mathbf{v} \\)": "Incorrect. The angle is not the norm.",
          "The direction of \\( \\mathbf{v} \\)": "Incorrect. The direction is not the norm.",
          "The dot product of \\( \\mathbf{v} \\) with itself": "Incorrect. The norm is the square root of the dot product of the vector with itself, not the dot product itself."
      }
  },
  {
      "question": "When is a matrix \\( A \\) considered positive definite?",
      "options": [
          "When all its eigenvalues are positive",
          "When all its eigenvalues are zero",
          "When all its eigenvalues are negative",
          "When all its diagonal elements are positive"
      ],
      "answer": "When all its eigenvalues are positive",
      "feedback": {
          "When all its eigenvalues are positive": "Correct! A matrix is considered positive definite if all its eigenvalues are positive.",
          "When all its eigenvalues are zero": "Incorrect. A matrix with all eigenvalues as zero would be singular, not positive definite.",
          "When all its eigenvalues are negative": "Incorrect. A matrix with all negative eigenvalues would be negative definite, not positive definite.",
          "When all its diagonal elements are positive": "Incorrect. Having positive diagonal elements alone does not make a matrix positive definite."
      }
  },
  {
      "question": "Which method of matrix factorization decomposes a matrix into its eigenvalues and eigenvectors?",
      "options": [
          "QR Decomposition",
          "LU Decomposition",
          "Singular Value Decomposition",
          "Eigenvalue Decomposition"
      ],
      "answer": "Eigenvalue Decomposition",
      "feedback": {
          "QR Decomposition": "Incorrect. QR decomposition factors a matrix into an orthogonal matrix and an upper triangular matrix, not into eigenvalues and eigenvectors.",
          "LU Decomposition": "Incorrect. LU decomposition factors a matrix into a lower triangular matrix and an upper triangular matrix, not into eigenvalues and eigenvectors.",
          "Singular Value Decomposition": "Incorrect. SVD factors a matrix into singular values and singular vectors, not into eigenvalues and eigenvectors.",
          "Eigenvalue Decomposition": "Correct! Eigenvalue decomposition factors a matrix into its eigenvalues and eigenvectors."
      }
  },
  {
      "question": "How is the projection of a vector \\( \\mathbf{u} \\) onto another vector \\( \\mathbf{v} \\) defined?",
      "options": [
          "\\( \\mathbf{u} + \\mathbf{v} \\)",
          "\\( \\frac{\\mathbf{u} \\cdot \\mathbf{v}}{\\mathbf{v} \\cdot \\mathbf{v}} \\mathbf{v} \\)",
          "\\( \\mathbf{u} \\times \\mathbf{v} \\)",
          "\\( \\mathbf{u} - \\mathbf{v} \\)"
      ],
      "answer": "\\( \\frac{\\mathbf{u} \\cdot \\mathbf{v}}{\\mathbf{v} \\cdot \\mathbf{v}} \\mathbf{v} \\)",
      "feedback": {
          "\\( \\mathbf{u} + \\mathbf{v} \\)": "Incorrect. This represents vector addition, not the projection.",
          "\\( \\frac{\\mathbf{u} \\cdot \\mathbf{v}}{\\mathbf{v} \\cdot \\mathbf{v}} \\mathbf{v} \\)": "Correct! This is the formula for the projection of \\( \\mathbf{u} \\) onto \\( \\mathbf{v} \\).",
          "\\( \\mathbf{u} \\times \\mathbf{v} \\)": "Incorrect. This represents the cross product, not the projection.",
          "\\( \\mathbf{u} - \\mathbf{v} \\)": "Incorrect. This represents vector subtraction, not the projection."
      }
  },
  {
      "question": "What is a random variable?",
      "options": [
          "A variable that is determined by a deterministic process",
          "A function that assigns a numerical value to each outcome in a sample space",
          "A variable that is always continuous",
          "A variable that is always discrete"
      ],
      "answer": "A function that assigns a numerical value to each outcome in a sample space",
      "feedback": {
          "A variable that is determined by a deterministic process": "Incorrect. A random variable is not deterministic, it is random.",
          "A function that assigns a numerical value to each outcome in a sample space": "Correct! A random variable is a function that assigns numerical values to outcomes in a sample space.",
          "A variable that is always continuous": "Incorrect. A random variable can be either continuous or discrete.",
          "A variable that is always discrete": "Incorrect. A random variable can be either discrete or continuous."
      }
  },
  {
      "question": "How is the determinant of a 2x2 matrix \\( \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\) calculated?",
      "options": [
          "ad - bc",
          "ab + cd",
          "ac - bd",
          "a + d"
      ],
      "answer": "ad - bc",
      "feedback": {
          "ad - bc": "Correct! The determinant of a 2x2 matrix is calculated as ad - bc.",
          "ab + cd": "Incorrect. This is not the formula for the determinant.",
          "ac - bd": "Incorrect. This is not the formula for the determinant.",
          "a + d": "Incorrect. This is not the formula for the determinant."
      }
  },
  {
      "question": "What is a defining property of a positive definite matrix \\( A \\)?",
      "options": [
          "\\( A = A^T \\)",
          "\\( x^T A x > 0 \\) for all non-zero \\( x \\)",
          "All eigenvalues are zero",
          "All eigenvalues are negative"
      ],
      "answer": "\\( x^T A x > 0 \\) for all non-zero \\( x \\)",
      "feedback": {
          "\\( A = A^T \\)": "Incorrect. This property is for symmetric matrices, not necessarily positive definite.",
          "\\( x^T A x > 0 \\) for all non-zero \\( x \\)": "Correct! This is a defining property of positive definite matrices.",
          "All eigenvalues are zero": "Incorrect. Positive definite matrices have positive eigenvalues.",
          "All eigenvalues are negative": "Incorrect. Positive definite matrices have positive eigenvalues."
      }
  },
  {
      "question": "What does the R-squared value indicate in linear regression?",
      "options": [
          "The slope of the regression line",
          "The intercept of the regression line",
          "The proportion of variance explained by the model",
          "The correlation between the independent variables"
      ],
      "answer": "The proportion of variance explained by the model",
      "feedback": {
          "The slope of the regression line": "Incorrect. The slope indicates the rate of change of the dependent variable.",
          "The intercept of the regression line": "Incorrect. The intercept is the expected value when all predictors are zero.",
          "The proportion of variance explained by the model": "Correct! R-squared represents the proportion of variance explained by the model.",
          "The correlation between the independent variables": "Incorrect. R-squared does not measure the correlation between independent variables."
      }
  },
  {
      "question": "Which distribution models the number of successes in a fixed number of trials?",
      "options": [
          "Uniform distribution",
          "Normal distribution",
          "Poisson distribution",
          "Binomial distribution"
      ],
      "answer": "Binomial distribution",
      "feedback": {
          "Uniform distribution": "Incorrect. The uniform distribution models equally likely outcomes.",
          "Normal distribution": "Incorrect. The normal distribution models continuous data with a symmetric distribution.",
          "Poisson distribution": "Incorrect. The Poisson distribution models the number of events in a fixed interval.",
          "Binomial distribution": "Correct! The binomial distribution models the number of successes in a fixed number of trials."
      }
  },
  {
      "question": "How is the determinant of a 2x2 matrix \\( \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\) calculated?",
      "options": [
          "ad - bc",
          "ab + cd",
          "ac - bd",
          "a + d"
      ],
      "answer": "ad - bc",
      "feedback": {
          "ad - bc": "Correct! The determinant of a 2x2 matrix is calculated as ad - bc.",
          "ab + cd": "Incorrect. This is not the formula for the determinant.",
          "ac - bd": "Incorrect. This is not the formula for the determinant.",
          "a + d": "Incorrect. This is not the formula for the determinant."
      }
  },
  {
      "question": "What can be said about the eigenvalues of a matrix?",
      "options": [
          "They are always positive.",
          "They can be complex numbers.",
          "They are always real numbers.",
          "They are always integers."
      ],
      "answer": "They can be complex numbers.",
      "feedback": {
          "They are always positive.": "Incorrect. Eigenvalues can be negative or complex as well.",
          "They can be complex numbers.": "Correct! Eigenvalues can indeed be complex numbers.",
          "They are always real numbers.": "Incorrect. Eigenvalues can be complex.",
          "They are always integers.": "Incorrect. Eigenvalues can be any real or complex number."
      }
  },
  {
      "question": "What does the rank of a matrix represent?",
      "options": [
          "The number of rows",
          "The number of columns",
          "The number of non-zero rows",
          "The number of linearly independent rows or columns"
      ],
      "answer": "The number of linearly independent rows or columns",
      "feedback": {
          "The number of rows": "Incorrect. The rank is not necessarily the number of rows.",
          "The number of columns": "Incorrect. The rank is not necessarily the number of columns.",
          "The number of non-zero rows": "Incorrect. The rank is the number of linearly independent rows or columns.",
          "The number of linearly independent rows or columns": "Correct! The rank is the number of linearly independent rows or columns."
      }
  },
  {
      "question": "Which operation is not used to compute the inverse of a matrix?",
      "options": [
          "Addition",
          "Subtraction",
          "Multiplication",
          "None of the above"
      ],
      "answer": "None of the above",
      "feedback": {
          "Addition": "Incorrect. Matrix inversion does not involve addition.",
          "Subtraction": "Incorrect. Matrix inversion does not involve subtraction.",
          "Multiplication": "Incorrect. Matrix inversion is a specific operation different from these.",
          "None of the above": "Correct! Matrix inversion is a distinct operation."
      }
  },
  {
      "question": "What is the form of a matrix A after eigenvalue decomposition?",
      "options": [
          "A = PDP^{-1}",
          "A = P^{-1}DP",
          "A = PDP'",
          "A = P'PD"
      ],
      "answer": "A = PDP^{-1}",
      "feedback": {
          "A = PDP^{-1}": "Correct! Eigenvalue decomposition is A = PDP^{-1}.",
          "A = P^{-1}DP": "Incorrect. The correct form is A = PDP^{-1}.",
          "A = PDP'": "Incorrect. The correct form is A = PDP^{-1}.",
          "A = P'PD": "Incorrect. The correct form is A = PDP^{-1}."
      }
  },
  {
      "question": "What is the mean of a standard normal distribution?",
      "options": [
          "0",
          "1",
          "2",
          "3"
      ],
      "answer": "0",
      "feedback": {
          "0": "Correct! The mean of a standard normal distribution is 0.",
          "1": "Incorrect. The mean of a standard normal distribution is not 1, it's 0.",
          "2": "Incorrect. The mean of a standard normal distribution is not 2, it's 0.",
          "3": "Incorrect. The mean of a standard normal distribution is not 3, it's 0."
      }
  },
  {
      "question": "In a binomial distribution, what does 'n' represent?",
      "options": [
          "Number of trials",
          "Number of successes",
          "Probability of success",
          "Probability of failure"
      ],
      "answer": "Number of trials",
      "feedback": {
          "Number of trials": "Correct! 'n' represents the number of trials in a binomial distribution.",
          "Number of successes": "Incorrect. 'n' does not represent the number of successes, it represents the number of trials.",
          "Probability of success": "Incorrect. 'n' does not represent the probability of success, it represents the number of trials.",
          "Probability of failure": "Incorrect. 'n' does not represent the probability of failure, it represents the number of trials."
      }
  },
  {
      "question": "What does the area under the curve of a probability density function (PDF) represent?",
      "options": [
          "The mean",
          "The standard deviation",
          "The variance",
          "The total probability"
      ],
      "answer": "The total probability",
      "feedback": {
          "The mean": "Incorrect. The area under the PDF does not represent the mean, it represents the total probability.",
          "The standard deviation": "Incorrect. The area under the PDF does not represent the standard deviation, it represents the total probability.",
          "The variance": "Incorrect. The area under the PDF does not represent the variance, it represents the total probability.",
          "The total probability": "Correct! The area under the PDF represents the total probability, which is always 1."
      }
  },
  {
      "question": "In optimization, what is a local minimum?",
      "options": [
          "The smallest value of the function over its entire range",
          "A value of the function that is lower than neighboring values",
          "The highest value of the function over its entire range",
          "A value of the function that is higher than neighboring values"
      ],
      "answer": "A value of the function that is lower than neighboring values",
      "feedback": {
          "The smallest value of the function over its entire range": "Incorrect. This describes a global minimum, not a local minimum.",
          "A value of the function that is lower than neighboring values": "Correct! A local minimum is a value that is lower than neighboring values.",
          "The highest value of the function over its entire range": "Incorrect. This describes a global maximum, not a local minimum.",
          "A value of the function that is higher than neighboring values": "Incorrect. This describes a local maximum, not a local minimum."
      }
  },
  {
      "question": "What is the gradient of a function?",
      "options": [
          "A scalar value representing the rate of change",
          "A vector indicating the direction and rate of fastest increase",
          "A matrix representing the second derivatives",
          "None of the above"
      ],
      "answer": "A vector indicating the direction and rate of fastest increase",
      "feedback": {
          "A scalar value representing the rate of change": "Incorrect. The gradient is not a scalar value, it's a vector.",
          "A vector indicating the direction and rate of fastest increase": "Correct! The gradient is a vector that points in the direction of the steepest ascent.",
          "A matrix representing the second derivatives": "Incorrect. The gradient is not a matrix, it's a vector.",
          "None of the above": "Incorrect. The gradient is a vector indicating the direction and rate of fastest increase."
      }
  },
  {
      "question": "Which method is commonly used for unconstrained optimization?",
      "options": [
          "Simplex method",
          "Newton's method",
          "Dual simplex method",
          "Barrier method"
      ],
      "answer": "Newton's method",
      "feedback": {
          "Simplex method": "Incorrect. The simplex method is used for linear programming, not for unconstrained optimization.",
          "Newton's method": "Correct! Newton's method is commonly used for unconstrained optimization.",
          "Dual simplex method": "Incorrect. The dual simplex method is used for linear programming, not for unconstrained optimization.",
          "Barrier method": "Incorrect. The barrier method is used for constrained optimization, not for unconstrained optimization."
      }
  },
  {
      "question": "What is the KKT condition used for?",
      "options": [
          "To determine the local minimum of a function",
          "To convert a non-linear problem to a linear one",
          "To test the optimality in constrained optimization",
          "To solve linear programming problems"
      ],
      "answer": "To test the optimality in constrained optimization",
      "feedback": {
          "To determine the local minimum of a function": "Incorrect. KKT conditions are used in constrained optimization.",
          "To convert a non-linear problem to a linear one": "Incorrect. KKT conditions do not convert problems.",
          "To test the optimality in constrained optimization": "Correct! KKT conditions are used to test optimality in constrained optimization.",
          "To solve linear programming problems": "Incorrect. KKT conditions are specific to non-linear constrained optimization."
      }
  },
  {
      "question": "What is the trace of a matrix?",
      "options": [
          "The sum of its diagonal elements",
          "The product of its eigenvalues",
          "The determinant of the matrix",
          "The sum of its eigenvalues"
      ],
      "answer": "The sum of its diagonal elements",
      "feedback": {
          "The sum of its diagonal elements": "Correct! The trace is the sum of the diagonal elements of a matrix.",
          "The product of its eigenvalues": "Incorrect. The product of its eigenvalues gives the determinant.",
          "The determinant of the matrix": "Incorrect. The determinant is not the same as the trace.",
          "The sum of its eigenvalues": "Incorrect. While the trace is equal to the sum of the eigenvalues, the trace is specifically the sum of the diagonal elements."
      }
  },
  {
      "question": "What does it mean for a set of vectors to be linearly independent?",
      "options": [
          "They are not scalar multiples of each other.",
          "Their dot product is zero.",
          "They span the vector space.",
          "No vector in the set can be written as a combination of the others."
      ],
      "answer": "No vector in the set can be written as a combination of the others.",
      "feedback": {
          "They are not scalar multiples of each other.": "Incorrect. This is not a sufficient condition for linear independence.",
          "Their dot product is zero.": "Incorrect. This describes orthogonality, not linear independence.",
          "They span the vector space.": "Incorrect. Spanning the vector space is related to the concept of a basis, not just independence.",
          "No vector in the set can be written as a combination of the others.": "Correct! This is the definition of linear independence."
      }
  },
  {
      "question": "What is the condition for two matrices to be multiplied?",
      "options": [
          "They must be square matrices.",
          "The number of rows in the first matrix must equal the number of columns in the second matrix.",
          "The number of columns in the first matrix must equal the number of rows in the second matrix.",
          "Both matrices must have the same dimensions."
      ],
      "answer": "The number of columns in the first matrix must equal the number of rows in the second matrix.",
      "feedback": {
          "They must be square matrices.": "Incorrect. Matrices do not need to be square to be multiplied.",
          "The number of rows in the first matrix must equal the number of columns in the second matrix.": "Incorrect. The correct condition is related to the columns of the first and rows of the second matrix.",
          "The number of columns in the first matrix must equal the number of rows in the second matrix.": "Correct! This is the condition for matrix multiplication.",
          "Both matrices must have the same dimensions.": "Incorrect. The dimensions do not need to be the same, just compatible."
      }
  },
  {
      "question": "What property does a symmetric matrix have?",
      "options": [
          "It is always invertible.",
          "It is equal to its transpose.",
          "Its eigenvalues are always positive.",
          "It is equal to its inverse."
      ],
      "answer": "It is equal to its transpose.",
      "feedback": {
          "It is always invertible.": "Incorrect. Not all symmetric matrices are invertible.",
          "It is equal to its transpose.": "Correct! A symmetric matrix is equal to its transpose.",
          "Its eigenvalues are always positive.": "Incorrect. This describes a positive definite matrix, not a symmetric matrix.",
          "It is equal to its inverse.": "Incorrect. This describes an orthogonal matrix, not a symmetric matrix."
      }
  },
  {
      "question": "What is the eigenvalue of an identity matrix?",
      "options": [
          "0",
          "1",
          "2",
          "Undefined"
      ],
      "answer": "1",
      "feedback": {
          "0": "Incorrect. The eigenvalue of the identity matrix is 1.",
          "1": "Correct! The eigenvalue of the identity matrix is 1.",
          "2": "Incorrect. The eigenvalue of the identity matrix is 1, not 2.",
          "Undefined": "Incorrect. The eigenvalue of the identity matrix is well-defined and is 1."
      }
  },
  {
      "question": "What does the rank of a matrix represent?",
      "options": [
          "The number of rows",
          "The number of columns",
          "The number of non-zero rows",
          "The number of linearly independent rows or columns"
      ],
      "answer": "The number of linearly independent rows or columns",
      "feedback": {
          "The number of rows": "Incorrect. The rank is not necessarily the number of rows.",
          "The number of columns": "Incorrect. The rank is not necessarily the number of columns.",
          "The number of non-zero rows": "Incorrect. The rank is not the number of linearly independent rows or columns, not the number of non-zero rows.",
          "The number of linearly independent rows or columns": "Correct! The rank is the number of linearly independent rows or columns."
      }
  },
  {
      "question": "Which matrix operation is undefined?",
      "options": [
          "Addition of two matrices",
          "Subtraction of two matrices",
          "Multiplication of a matrix by a scalar",
          "Division of a matrix by a matrix"
      ],
      "answer": "Division of a matrix by a matrix",
      "feedback": {
          "Addition of two matrices": "Incorrect. Addition of two matrices is a well-defined operation.",
          "Subtraction of two matrices": "Incorrect. Subtraction of two matrices is a well-defined operation.",
          "Multiplication of a matrix by a scalar": "Incorrect. Multiplication of a matrix by a scalar is a well-defined operation.",
          "Division of a matrix by a matrix": "Correct! Division of one matrix by another is not a defined operation."
      }
  },
  {
      "question": "What is the inverse of a matrix A, if it exists?",
      "options": [
          "A matrix that when multiplied by A gives the identity matrix",
          "A matrix that when added to A gives the zero matrix",
          "A matrix that when subtracted from A gives the zero matrix",
          "A matrix that when divided by A gives the identity matrix"
      ],
      "answer": "A matrix that when multiplied by A gives the identity matrix",
      "feedback": {
          "A matrix that when multiplied by A gives the identity matrix": "Correct! The inverse of a matrix A, when it exists, is a matrix that when multiplied by A gives the identity matrix.",
          "A matrix that when added to A gives the zero matrix": "Incorrect. The inverse of a matrix is not defined this way.",
          "A matrix that when subtracted from A gives the zero matrix": "Incorrect. The inverse of a matrix is not defined this way.",
          "A matrix that when divided by A gives the identity matrix": "Incorrect. Matrix division is not defined."
      }
  },
  {
      "question": "What is the characteristic equation of a matrix A?",
      "options": [
          "det(A - \u03bbI) = 0",
          "tr(A - \u03bbI) = 0",
          "det(A + \u03bbI) = 0",
          "tr(A + \u03bbI) = 0"
      ],
      "answer": "det(A - \u03bbI) = 0",
      "feedback": {
          "det(A - \u03bbI) = 0": "Correct! The characteristic equation of a matrix A is det(A - \u03bbI) = 0.",
          "tr(A - \u03bbI) = 0": "Incorrect. The characteristic equation involves the determinant, not the trace.",
          "det(A + \u03bbI) = 0": "Incorrect. The correct equation is det(A - \u03bbI) = 0, not det(A + \u03bbI) = 0.",
          "tr(A + \u03bbI) = 0": "Incorrect. The characteristic equation involves the determinant, not the trace."
      }
  },
  {
      "question": "What is the property of an orthogonal matrix Q?",
      "options": [
          "Q^TQ = I",
          "QQ = I",
          "Q = Q^T",
          "Q^T = I"
      ],
      "answer": "Q^TQ = I",
      "feedback": {
          "Q^TQ = I": "Correct! For an orthogonal matrix Q, Q^TQ = I.",
          "QQ = I": "Incorrect. The correct relation is Q^TQ = I.",
          "Q = Q^T": "Incorrect. This is true for symmetric matrices, not orthogonal ones.",
          "Q^T = I": "Incorrect. The transpose of an orthogonal matrix is not necessarily the identity matrix."
      }
  },
  {
      "question": "What defines a positive definite matrix?",
      "options": [
          "All its eigenvalues are positive",
          "All its eigenvalues are negative",
          "All its diagonal elements are positive",
          "All its diagonal elements are negative"
      ],
      "answer": "All its eigenvalues are positive",
      "feedback": {
          "All its eigenvalues are positive": "Correct! A positive definite matrix has all positive eigenvalues.",
          "All its eigenvalues are negative": "Incorrect. This describes a negative definite matrix.",
          "All its diagonal elements are positive": "Incorrect. Positive diagonal elements alone do not define a positive definite matrix.",
          "All its diagonal elements are negative": "Incorrect. This describes a negative definite matrix."
      }
  },
  {
      "question": "What is the outcome of multiplying a matrix by its transpose?",
      "options": [
          "A symmetric matrix",
          "A skew-symmetric matrix",
          "A diagonal matrix",
          "An orthogonal matrix"
      ],
      "answer": "A symmetric matrix",
      "feedback": {
          "A symmetric matrix": "Correct! Multiplying a matrix by its transpose results in a symmetric matrix.",
          "A skew-symmetric matrix": "Incorrect. This is not the result of multiplying a matrix by its transpose.",
          "A diagonal matrix": "Incorrect. The result is a symmetric matrix, not necessarily diagonal.",
          "An orthogonal matrix": "Incorrect. This is not the result of multiplying a matrix by its transpose."
      }
  },
  {
      "question": "What is the determinant of a singular matrix?",
      "options": [
          "0",
          "1",
          "-1",
          "Undefined"
      ],
      "answer": "0",
      "feedback": {
          "0": "Correct! The determinant of a singular matrix is 0.",
          "1": "Incorrect. The determinant of a singular matrix is 0.",
          "-1": "Incorrect. The determinant of a singular matrix is 0.",
          "Undefined": "Incorrect. The determinant of a singular matrix is defined as 0."
      }
  },
  {
      "question": "What is a property of eigenvalues of a matrix?",
      "options": [
          "They are always positive.",
          "They can be complex numbers.",
          "They are always real numbers.",
          "They are always integers."
      ],
      "answer": "They can be complex numbers.",
      "feedback": {
          "They are always positive.": "Incorrect. Eigenvalues can be negative or complex as well.",
          "They can be complex numbers.": "Correct! Eigenvalues can indeed be complex numbers.",
          "They are always real numbers.": "Incorrect. Eigenvalues can be complex.",
          "They are always integers.": "Incorrect. Eigenvalues can be any real or complex number."
      }
  },
  {
      "question": "Which type of matrix has an inverse?",
      "options": [
          "A singular matrix",
          "A matrix with a determinant of 0",
          "A non-square matrix",
          "A non-singular square matrix"
      ],
      "answer": "A non-singular square matrix",
      "feedback": {
          "A singular matrix": "Incorrect. A singular matrix does not have an inverse.",
          "A matrix with a determinant of 0": "Incorrect. A matrix with a determinant of 0 is singular and does not have an inverse.",
          "A non-square matrix": "Incorrect. Only square matrices can have inverses.",
          "A non-singular square matrix": "Correct! A non-singular square matrix has an inverse."
      }
  },
  {
      "question": "What is a diagonal matrix?",
      "options": [
          "A matrix with non-zero elements only on its main diagonal",
          "A matrix with non-zero elements only above its main diagonal",
          "A matrix with non-zero elements only below its main diagonal",
          "A matrix with zero elements on its main diagonal"
      ],
      "answer": "A matrix with non-zero elements only on its main diagonal",
      "feedback": {
          "A matrix with non-zero elements only on its main diagonal": "Correct! A diagonal matrix has non-zero elements only on its main diagonal.",
          "A matrix with non-zero elements only above its main diagonal": "Incorrect. This describes an upper triangular matrix.",
          "A matrix with non-zero elements only below its main diagonal": "Incorrect. This describes a lower triangular matrix.",
          "A matrix with zero elements on its main diagonal": "Incorrect. This does not describe a diagonal matrix."
      }
  },
  {
      "question": "What is the trace of a matrix?",
      "options": [
          "The sum of its diagonal elements",
          "The product of its eigenvalues",
          "The determinant of the matrix",
          "The sum of its eigenvalues"
      ],
      "answer": "The sum of its diagonal elements",
      "feedback": {
          "The sum of its diagonal elements": "Correct! The trace is the sum of the diagonal elements of a matrix.",
          "The product of its eigenvalues": "Incorrect. The product of its eigenvalues gives the determinant.",
          "The determinant of the matrix": "Incorrect. The determinant is not the same as the trace.",
          "The sum of its eigenvalues": "Incorrect. While the trace is equal to the sum of the eigenvalues, the trace is specifically the sum of the diagonal elements."
      }
  },
  {
      "question": "What does the determinant of a matrix indicate?",
      "options": [
          "The volume scaling factor of the linear transformation",
          "The trace of the matrix",
          "The rank of the matrix",
          "The number of non-zero rows"
      ],
      "answer": "The volume scaling factor of the linear transformation",
      "feedback": {
          "The volume scaling factor of the linear transformation": "Correct! The determinant indicates the volume scaling factor of the linear transformation.",
          "The trace of the matrix": "Incorrect. The trace is the sum of the diagonal elements.",
          "The rank of the matrix": "Incorrect. The rank is the number of linearly independent rows or columns.",
          "The number of non-zero rows": "Incorrect. The determinant does not indicate the number of non-zero rows."
      }
  },
  {
      "question": "What is the expected value of a fair six-sided die?",
      "options": [
          "3.5",
          "2.5",
          "3",
          "4"
      ],
      "answer": "3.5",
      "feedback": {
          "3.5": "Correct! The expected value of a fair six-sided die is 3.5.",
          "2.5": "Incorrect. This is not the expected value of a fair six-sided die.",
          "3": "Incorrect. This is not the expected value of a fair six-sided die.",
          "4": "Incorrect. This is not the expected value of a fair six-sided die."
      }
  },
  {
      "question": "In linear regression, what does the R-squared value indicate?",
      "options": [
          "The slope of the regression line",
          "The intercept of the regression line",
          "The proportion of variance explained by the model",
          "The correlation between the independent variables"
      ],
      "answer": "The proportion of variance explained by the model",
      "feedback": {
          "The slope of the regression line": "Incorrect. The R-squared value represents the proportion of variance explained by the model.",
          "The intercept of the regression line": "Incorrect. The R-squared value represents the proportion of variance explained by the model.",
          "The proportion of variance explained by the model": "Correct! The R-squared value represents the proportion of variance explained by the model.",
          "The correlation between the independent variables": "Incorrect. The R-squared value represents the proportion of variance explained by the model."
      }
  },
  {
      "question": "In probability, what does the complement of an event \\(A\\) represent?",
      "options": [
          "The probability of A occurring",
          "The union of A with another event",
          "The probability of A not occurring",
          "The intersection of A with another event"
      ],
      "answer": "The probability of A not occurring",
      "feedback": {
          "The probability of A occurring": "Incorrect. The complement of an event represents the probability of it not occurring.",
          "The union of A with another event": "Incorrect. The complement of an event represents the probability of it not occurring.",
          "The probability of A not occurring": "Correct! The complement of an event represents the probability of it not occurring.",
          "The intersection of A with another event": "Incorrect. The complement of an event represents the probability of it not occurring."
      }
  },
  {
      "question": "What is the main purpose of a confidence interval?",
      "options": [
          "To provide a range of values within which the true population parameter is expected to fall",
          "To test the significance of a hypothesis",
          "To determine the sample size needed for a study",
          "To calculate the mean of a sample"
      ],
      "answer": "To provide a range of values within which the true population parameter is expected to fall",
      "feedback": {
          "To provide a range of values within which the true population parameter is expected to fall": "Correct! A confidence interval provides a range of values within which the true population parameter is expected to fall.",
          "To test the significance of a hypothesis": "Incorrect. A confidence interval does not test the significance of a hypothesis.",
          "To determine the sample size needed for a study": "Incorrect. A confidence interval does not determine the sample size needed for a study.",
          "To calculate the mean of a sample": "Incorrect. A confidence interval does not calculate the mean of a sample."
      }
  },
  {
      "question": "What does the Central Limit Theorem state?",
      "options": [
          "The distribution of sample means approaches a normal distribution as the sample size increases",
          "The distribution of sample means approaches a uniform distribution as the sample size increases",
          "The distribution of sample means approaches a binomial distribution as the sample size increases",
          "The distribution of sample means approaches a Poisson distribution as the sample size increases"
      ],
      "answer": "The distribution of sample means approaches a normal distribution as the sample size increases",
      "feedback": {
          "The distribution of sample means approaches a normal distribution as the sample size increases": "Correct! The Central Limit Theorem states that the distribution of sample means approaches a normal distribution as the sample size increases.",
          "The distribution of sample means approaches a uniform distribution as the sample size increases": "Incorrect. The Central Limit Theorem states that the distribution of sample means approaches a normal distribution as the sample size increases.",
          "The distribution of sample means approaches a binomial distribution as the sample size increases": "Incorrect. The Central Limit Theorem states that the distribution of sample means approaches a normal distribution as the sample size increases.",
          "The distribution of sample means approaches a Poisson distribution as the sample size increases": "Incorrect. The Central Limit Theorem states that the distribution of sample means approaches a normal distribution as the sample size increases."
      }
  },
  {
      "question": "What is the main purpose of regression analysis?",
      "options": [
          "To establish causality between variables",
          "To predict the value of a dependent variable based on an independent variable",
          "To determine the distribution of a sample",
          "To calculate the mean and standard deviation of a dataset"
      ],
      "answer": "To predict the value of a dependent variable based on an independent variable",
      "feedback": {
          "To establish causality between variables": "Incorrect. Regression analysis does not establish causality.",
          "To predict the value of a dependent variable based on an independent variable": "Correct! Regression analysis is used to predict the value of a dependent variable based on an independent variable.",
          "To determine the distribution of a sample": "Incorrect. Regression analysis is not used to determine the distribution of a sample.",
          "To calculate the mean and standard deviation of a dataset": "Incorrect. Regression analysis is not used to calculate the mean and standard deviation of a dataset."
      }
  },
  {
      "question": "What is the gradient descent update rule?",
      "options": [
          "It randomly changes parameters to find the best fit",
          "It keeps the parameters constant throughout the process",
          "It adjusts the loss function directly",
          "It iteratively updates the parameters in the direction of the steepest descent of the loss function"
      ],
      "answer": "It iteratively updates the parameters in the direction of the steepest descent of the loss function",
      "feedback": {
          "It randomly changes parameters to find the best fit": "Incorrect. The gradient descent update rule involves iteratively adjusting parameters.",
          "It keeps the parameters constant throughout the process": "Incorrect. The gradient descent update rule involves iteratively adjusting parameters.",
          "It adjusts the loss function directly": "Incorrect. The gradient descent update rule involves iteratively adjusting parameters.",
          "It iteratively updates the parameters in the direction of the steepest descent of the loss function": "Correct! The gradient descent update rule involves iteratively adjusting parameters in the direction of the steepest descent."
      }
  },
  {
      "question": "Which of the following is a first-order optimization algorithm?",
      "options": [
          "Newton's Method",
          "Conjugate Gradient Method",
          "Gradient Descent",
          "Quasi-Newton Method"
      ],
      "answer": "Gradient Descent",
      "feedback": {
          "Newton's Method": "Incorrect. Gradient Descent is a first-order optimization algorithm.",
          "Conjugate Gradient Method": "Incorrect. Gradient Descent is a first-order optimization algorithm.",
          "Gradient Descent": "Correct! Gradient Descent is a first-order optimization algorithm.",
          "Quasi-Newton Method": "Incorrect. Gradient Descent is a first-order optimization algorithm."
      }
  },
  {
      "question": "What does the term 'convergence' mean in the context of optimization algorithms?",
      "options": [
          "The algorithm always finds the global minimum",
          "The algorithm always finds the global maximum",
          "The algorithm approaches a solution as iterations increase",
          "The algorithm stops after a fixed number of iterations"
      ],
      "answer": "The algorithm approaches a solution as iterations increase",
      "feedback": {
          "The algorithm always finds the global minimum": "Incorrect. Convergence means the algorithm approaches a solution as iterations increase.",
          "The algorithm always finds the global maximum": "Incorrect. Convergence means the algorithm approaches a solution as iterations increase.",
          "The algorithm approaches a solution as iterations increase": "Correct! Convergence means the algorithm approaches a solution as iterations increase.",
          "The algorithm stops after a fixed number of iterations": "Incorrect. Convergence means the algorithm approaches a solution as iterations increase."
      }
  },
  {
      "question": "What is the primary goal when optimizing a loss function?",
      "options": [
          "To reach the maximum of the loss function",
          "To find a balance between bias and variance",
          "To reach the minimum of the loss function",
          "To maintain the loss function at a constant value"
      ],
      "answer": "To reach the minimum of the loss function",
      "feedback": {
          "To reach the maximum of the loss function": "Incorrect. The primary goal is to reach the minimum of the loss function.",
          "To find a balance between bias and variance": "Incorrect. The primary goal is to reach the minimum of the loss function.",
          "To reach the minimum of the loss function": "Correct! The primary goal is to reach the minimum of the loss function.",
          "To maintain the loss function at a constant value": "Incorrect. The primary goal is to reach the minimum of the loss function."
      }
  },
  {
      "question": "What is the purpose of regularization in machine learning models?",
      "options": [
          "To reduce the complexity of the model",
          "To increase the complexity of the model",
          "To eliminate the need for cross-validation",
          "To improve model accuracy by adding noise"
      ],
      "answer": "To reduce the complexity of the model",
      "feedback": {
          "To reduce the complexity of the model": "Correct! Regularization is used to reduce the complexity of the model and prevent overfitting.",
          "To increase the complexity of the model": "Incorrect. Regularization reduces the complexity of the model.",
          "To eliminate the need for cross-validation": "Incorrect. Regularization does not eliminate the need for cross-validation.",
          "To improve model accuracy by adding noise": "Incorrect. Regularization does not improve model accuracy by adding noise."
      }
  },
  {
      "question": "What happens if the learning rate is too high in gradient descent?",
      "options": [
          "It slows down the convergence",
          "It makes no difference to the optimization process",
          "It can cause the algorithm to overshoot the minimum",
          "It ensures faster convergence to the minimum"
      ],
      "answer": "It can cause the algorithm to overshoot the minimum",
      "feedback": {
          "It slows down the convergence": "Incorrect. A high learning rate might lead to instability and divergence.",
          "It makes no difference to the optimization process": "Incorrect. A high learning rate can affect the optimization process.",
          "It can cause the algorithm to overshoot the minimum": "Correct! A high learning rate might lead to instability and divergence.",
          "It ensures faster convergence to the minimum": "Incorrect. A high learning rate might lead to instability and divergence."
      }
  },
  {
      "question": "What does a random approach to optimization result in?",
      "options": [
          "Loss consistently decreases",
          "Loss reaches its global minimum",
          "Loss does not decrease significantly",
          "Loss remains constant"
      ],
      "answer": "Loss does not decrease significantly",
      "feedback": {
          "Loss consistently decreases": "Incorrect. While the loss might remain nearly constant, the key point is that it does not decrease significantly.",
          "Loss reaches its global minimum": "Incorrect. While the loss might remain nearly constant, the key point is that it does not decrease significantly.",
          "Loss does not decrease significantly": "Correct! A random approach to optimization does not lead to significant decreases in loss.",
          "Loss remains constant": "Incorrect. While the loss might remain nearly constant, the key point is that it does not decrease significantly."
      }
  },
  {
      "question": "How does following the slope help in optimization?",
      "options": [
          "It reduces the number of iterations needed",
          "It ensures the loss function remains unchanged",
          "It guides towards the direction of steepest descent, leading to faster convergence",
          "It helps in increasing the learning rate dynamically"
      ],
      "answer": "It guides towards the direction of steepest descent, leading to faster convergence",
      "feedback": {
          "It reduces the number of iterations needed": "Incorrect. Following the slope helps in finding the direction of steepest descent, not in reducing iterations directly.",
          "It ensures the loss function remains unchanged": "Incorrect. Following the slope guides towards the direction of steepest descent.",
          "It guides towards the direction of steepest descent, leading to faster convergence": "Correct! Following the slope helps in finding the direction of steepest descent.",
          "It helps in increasing the learning rate dynamically": "Incorrect. Following the slope helps in finding the direction of steepest descent."
      }
  },
  {
      "question": "What is the convergence criterion in gradient descent?",
      "options": [
          "When the loss function becomes negative",
          "When the loss function starts increasing",
          "When the gradient of the loss function is close to zero",
          "When the learning rate is adjusted dynamically"
      ],
      "answer": "When the gradient of the loss function is close to zero",
      "feedback": {
          "When the loss function becomes negative": "Incorrect. The convergence criterion is when the gradient of the loss function is close to zero.",
          "When the loss function starts increasing": "Incorrect. The convergence criterion is when the gradient of the loss function is close to zero.",
          "When the gradient of the loss function is close to zero": "Correct! The convergence criterion in gradient descent is when the gradient of the loss function is close to zero.",
          "When the learning rate is adjusted dynamically": "Incorrect. The convergence criterion is when the gradient of the loss function is close to zero."
      }
  },
  {
      "question": "Which of the following is an example of a supervised learning algorithm?",
      "options": [
          "K-Means Clustering",
          "Principal Component Analysis",
          "Linear Regression",
          "t-SNE"
      ],
      "answer": "Linear Regression",
      "feedback": {
          "K-Means Clustering": "Incorrect. K-Means Clustering is an unsupervised learning algorithm.",
          "Principal Component Analysis": "Incorrect. PCA is a dimensionality reduction technique.",
          "Linear Regression": "Correct! Linear Regression is a supervised learning algorithm.",
          "t-SNE": "Incorrect. t-SNE is a dimensionality reduction technique."
      }
  },
  {
      "question": "Which of the following operations cannot be performed on a matrix?",
      "options": [
          "Addition",
          "Multiplication",
          "Subtraction",
          "Differentiation"
      ],
      "answer": "Differentiation",
      "feedback": {
          "Addition": "Addition of matrices is a valid operation.",
          "Multiplication": "Multiplication of matrices is a valid operation.",
          "Subtraction": "Subtraction of matrices is a valid operation.",
          "Differentiation": "Correct! Differentiation is not typically defined for matrices."
      }
  },
  {
      "question": "A subspace of a vector space is characterized by:",
      "options": [
          "Not containing the zero vector",
          "Being closed under addition and scalar multiplication",
          "Being infinite",
          "Having at least one vector"
      ],
      "answer": "Being closed under addition and scalar multiplication",
      "feedback": {
          "Not containing the zero vector": "A subspace must contain the zero vector.",
          "Being closed under addition and scalar multiplication": "Correct! A subspace is closed under addition and scalar multiplication.",
          "Being infinite": "A subspace does not have to be infinite.",
          "Having at least one vector": "Having at least one vector does not fully define a subspace."
      }
  },
  {
      "question": "The rank of a matrix indicates:",
      "options": [
          "The number of rows",
          "The number of columns",
          "The number of linearly independent rows or columns",
          "The determinant of the matrix"
      ],
      "answer": "The number of linearly independent rows or columns",
      "feedback": {
          "The number of rows": "Incorrect. The rank is not simply the number of rows.",
          "The number of columns": "Incorrect. The rank is not simply the number of columns.",
          "The number of linearly independent rows or columns": "Correct! The rank is the number of linearly independent rows or columns.",
          "The determinant of the matrix": "Incorrect. The determinant is a scalar value representing the matrix's properties."
      }
  },
  {
      "question": "Which of the following properties does a positive definite matrix \\( A \\) have?",
      "options": [
          "\\( A = A^T \\)",
          "\\( x^T A x > 0 \\) for all non-zero \\( x \\)",
          "All eigenvalues are zero",
          "All eigenvalues are negative",
          "A value of the function that is lower than neighboring values"
      ],
      "answer": "\\( x^T A x > 0 \\) for all non-zero \\( x \\)",
      "feedback": {
          "\\( A = A^T \\)": "Incorrect. This property is for symmetric matrices, but not necessarily positive definite.",
          "\\( x^T A x > 0 \\) for all non-zero \\( x \\)": "Correct! This is a defining property of positive definite matrices.",
          "All eigenvalues are zero": "Incorrect. Positive definite matrices have positive eigenvalues.",
          "All eigenvalues are negative": "Incorrect. Positive definite matrices have positive eigenvalues."
      }
  },
  {
      "question": "Which of the following is an example of matrix factorization?",
      "options": [
          "LU Decomposition",
          "Matrix Multiplication",
          "Matrix Addition",
          "Matrix Transposition"
      ],
      "answer": "LU Decomposition",
      "feedback": {
          "LU Decomposition": "Correct! LU Decomposition is a type of matrix factorization.",
          "Matrix Multiplication": "Matrix multiplication is an operation, not a factorization.",
          "Matrix Addition": "Matrix addition is an operation, not a factorization.",
          "Matrix Transposition": "Matrix transposition is an operation, not a factorization."
      }
  },
  {
      "question": "In the context of probability, a random variable is:",
      "options": [
          "A deterministic quantity",
          "A function that assigns values to outcomes",
          "Always continuous",
          "Always discrete"
      ],
      "answer": "A function that assigns values to outcomes",
      "feedback": {
          "A deterministic quantity": "A random variable is not deterministic.",
          "A function that assigns values to outcomes": "Correct! A random variable assigns values to outcomes.",
          "Always continuous": "Random variables can be either continuous or discrete.",
          "Always discrete": "Random variables can be either discrete or continuous."
      }
  },
  {
      "question": "The probability density function (PDF) is used to describe:",
      "options": [
          "Discrete random variables",
          "Continuous random variables",
          "The mean of a random variable",
          "The variance of a random variable"
      ],
      "answer": "Continuous random variables",
      "feedback": {
          "Discrete random variables": "Incorrect. The probability mass function (PMF) is used for discrete random variables.",
          "Continuous random variables": "Correct! The PDF describes continuous random variables.",
          "The mean of a random variable": "Incorrect. The PDF does not describe the mean.",
          "The variance of a random variable": "Incorrect. The PDF does not describe the variance."
      }
  },
  {
      "question": "The derivative of a function \\( f(x) \\) represents:",
      "options": [
          "The area under the curve of \\( f(x) \\)",
          "The slope of the tangent line to \\( f(x) \\)",
          "The value of \\( f(x) \\) at \\( x \\)",
          "The maximum value of \\( f(x) \\)"
      ],
      "answer": "The slope of the tangent line to \\( f(x) \\)",
      "feedback": {
          "The area under the curve of \\( f(x) \\)": "The integral represents the area under the curve.",
          "The slope of the tangent line to \\( f(x) \\)": "Correct! The derivative represents the slope of the tangent line.",
          "The value of \\( f(x) \\) at \\( x \\)": "The derivative is not the value of the function.",
          "The maximum value of \\( f(x) \\)": "The derivative can help find maxima, but it is not the maximum value."
      }
  }
]